// Code generated by ent, DO NOT EDIT.

package ent

import (
	"context"
	"database/sql/driver"
	"fmt"

	"entgo.io/contrib/entgql"
	"entgo.io/ent/dialect/sql"
	"github.com/99designs/gqlgen/graphql"
	"github.com/looplj/axonhub/internal/ent/apikey"
	"github.com/looplj/axonhub/internal/ent/channel"
	"github.com/looplj/axonhub/internal/ent/channelperformance"
	"github.com/looplj/axonhub/internal/ent/datastorage"
	"github.com/looplj/axonhub/internal/ent/project"
	"github.com/looplj/axonhub/internal/ent/request"
	"github.com/looplj/axonhub/internal/ent/requestexecution"
	"github.com/looplj/axonhub/internal/ent/role"
	"github.com/looplj/axonhub/internal/ent/system"
	"github.com/looplj/axonhub/internal/ent/thread"
	"github.com/looplj/axonhub/internal/ent/trace"
	"github.com/looplj/axonhub/internal/ent/usagelog"
	"github.com/looplj/axonhub/internal/ent/user"
	"github.com/looplj/axonhub/internal/ent/userproject"
	"github.com/looplj/axonhub/internal/ent/userrole"
)

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *APIKeyQuery) CollectFields(ctx context.Context, satisfies ...string) (*APIKeyQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *APIKeyQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(apikey.Columns))
		selectedFields = []string{apikey.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[apikey.FieldUserID]; !ok {
				selectedFields = append(selectedFields, apikey.FieldUserID)
				fieldSeen[apikey.FieldUserID] = struct{}{}
			}

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[apikey.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, apikey.FieldProjectID)
				fieldSeen[apikey.FieldProjectID] = struct{}{}
			}

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*APIKey) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"api_key_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(apikey.RequestsColumn), ids...))
						})
						if err := query.GroupBy(apikey.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*APIKey) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(apikey.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[apikey.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, apikey.FieldCreatedAt)
				fieldSeen[apikey.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[apikey.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, apikey.FieldUpdatedAt)
				fieldSeen[apikey.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[apikey.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, apikey.FieldDeletedAt)
				fieldSeen[apikey.FieldDeletedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[apikey.FieldUserID]; !ok {
				selectedFields = append(selectedFields, apikey.FieldUserID)
				fieldSeen[apikey.FieldUserID] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[apikey.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, apikey.FieldProjectID)
				fieldSeen[apikey.FieldProjectID] = struct{}{}
			}
		case "key":
			if _, ok := fieldSeen[apikey.FieldKey]; !ok {
				selectedFields = append(selectedFields, apikey.FieldKey)
				fieldSeen[apikey.FieldKey] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[apikey.FieldName]; !ok {
				selectedFields = append(selectedFields, apikey.FieldName)
				fieldSeen[apikey.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[apikey.FieldStatus]; !ok {
				selectedFields = append(selectedFields, apikey.FieldStatus)
				fieldSeen[apikey.FieldStatus] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[apikey.FieldScopes]; !ok {
				selectedFields = append(selectedFields, apikey.FieldScopes)
				fieldSeen[apikey.FieldScopes] = struct{}{}
			}
		case "profiles":
			if _, ok := fieldSeen[apikey.FieldProfiles]; !ok {
				selectedFields = append(selectedFields, apikey.FieldProfiles)
				fieldSeen[apikey.FieldProfiles] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type apikeyPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []APIKeyPaginateOption
}

func newAPIKeyPaginateArgs(rv map[string]any) *apikeyPaginateArgs {
	args := &apikeyPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &APIKeyOrder{Field: &APIKeyOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithAPIKeyOrder(order))
			}
		case *APIKeyOrder:
			if v != nil {
				args.opts = append(args.opts, WithAPIKeyOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*APIKeyWhereInput); ok {
		args.opts = append(args.opts, WithAPIKeyFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ChannelQuery) CollectFields(ctx context.Context, satisfies ...string) (*ChannelQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ChannelQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(channel.Columns))
		selectedFields = []string{channel.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Channel) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"channel_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(channel.RequestsColumn), ids...))
						})
						if err := query.GroupBy(channel.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Channel) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(channel.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})

		case "executions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestExecutionClient{config: _q.config}).Query()
			)
			args := newRequestExecutionPaginateArgs(fieldArgs(ctx, new(RequestExecutionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestExecutionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Channel) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"channel_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(channel.ExecutionsColumn), ids...))
						})
						if err := query.GroupBy(channel.ExecutionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Channel) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Executions)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestexecutionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(channel.ExecutionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedExecutions(alias, func(wq *RequestExecutionQuery) {
				*wq = *query
			})

		case "usageLogs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UsageLogClient{config: _q.config}).Query()
			)
			args := newUsageLogPaginateArgs(fieldArgs(ctx, new(UsageLogWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUsageLogPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Channel) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"channel_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(channel.UsageLogsColumn), ids...))
						})
						if err := query.GroupBy(channel.UsageLogsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Channel) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UsageLogs)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, usagelogImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(channel.UsageLogsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsageLogs(alias, func(wq *UsageLogQuery) {
				*wq = *query
			})

		case "channelPerformance":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelPerformanceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelperformanceImplementors)...); err != nil {
				return err
			}
			_q.withChannelPerformance = query
		case "createdAt":
			if _, ok := fieldSeen[channel.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, channel.FieldCreatedAt)
				fieldSeen[channel.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[channel.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, channel.FieldUpdatedAt)
				fieldSeen[channel.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[channel.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, channel.FieldDeletedAt)
				fieldSeen[channel.FieldDeletedAt] = struct{}{}
			}
		case "type":
			if _, ok := fieldSeen[channel.FieldType]; !ok {
				selectedFields = append(selectedFields, channel.FieldType)
				fieldSeen[channel.FieldType] = struct{}{}
			}
		case "baseURL":
			if _, ok := fieldSeen[channel.FieldBaseURL]; !ok {
				selectedFields = append(selectedFields, channel.FieldBaseURL)
				fieldSeen[channel.FieldBaseURL] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[channel.FieldName]; !ok {
				selectedFields = append(selectedFields, channel.FieldName)
				fieldSeen[channel.FieldName] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[channel.FieldStatus]; !ok {
				selectedFields = append(selectedFields, channel.FieldStatus)
				fieldSeen[channel.FieldStatus] = struct{}{}
			}
		case "supportedModels":
			if _, ok := fieldSeen[channel.FieldSupportedModels]; !ok {
				selectedFields = append(selectedFields, channel.FieldSupportedModels)
				fieldSeen[channel.FieldSupportedModels] = struct{}{}
			}
		case "tags":
			if _, ok := fieldSeen[channel.FieldTags]; !ok {
				selectedFields = append(selectedFields, channel.FieldTags)
				fieldSeen[channel.FieldTags] = struct{}{}
			}
		case "defaultTestModel":
			if _, ok := fieldSeen[channel.FieldDefaultTestModel]; !ok {
				selectedFields = append(selectedFields, channel.FieldDefaultTestModel)
				fieldSeen[channel.FieldDefaultTestModel] = struct{}{}
			}
		case "settings":
			if _, ok := fieldSeen[channel.FieldSettings]; !ok {
				selectedFields = append(selectedFields, channel.FieldSettings)
				fieldSeen[channel.FieldSettings] = struct{}{}
			}
		case "orderingWeight":
			if _, ok := fieldSeen[channel.FieldOrderingWeight]; !ok {
				selectedFields = append(selectedFields, channel.FieldOrderingWeight)
				fieldSeen[channel.FieldOrderingWeight] = struct{}{}
			}
		case "errorMessage":
			if _, ok := fieldSeen[channel.FieldErrorMessage]; !ok {
				selectedFields = append(selectedFields, channel.FieldErrorMessage)
				fieldSeen[channel.FieldErrorMessage] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type channelPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ChannelPaginateOption
}

func newChannelPaginateArgs(rv map[string]any) *channelPaginateArgs {
	args := &channelPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ChannelOrder{Field: &ChannelOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithChannelOrder(order))
			}
		case *ChannelOrder:
			if v != nil {
				args.opts = append(args.opts, WithChannelOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ChannelWhereInput); ok {
		args.opts = append(args.opts, WithChannelFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ChannelPerformanceQuery) CollectFields(ctx context.Context, satisfies ...string) (*ChannelPerformanceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ChannelPerformanceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(channelperformance.Columns))
		selectedFields = []string{channelperformance.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			_q.withChannel = query
			if _, ok := fieldSeen[channelperformance.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldChannelID)
				fieldSeen[channelperformance.FieldChannelID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[channelperformance.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldCreatedAt)
				fieldSeen[channelperformance.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[channelperformance.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldUpdatedAt)
				fieldSeen[channelperformance.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[channelperformance.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldDeletedAt)
				fieldSeen[channelperformance.FieldDeletedAt] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[channelperformance.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldChannelID)
				fieldSeen[channelperformance.FieldChannelID] = struct{}{}
			}
		case "successRate":
			if _, ok := fieldSeen[channelperformance.FieldSuccessRate]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldSuccessRate)
				fieldSeen[channelperformance.FieldSuccessRate] = struct{}{}
			}
		case "avgLatencyMs":
			if _, ok := fieldSeen[channelperformance.FieldAvgLatencyMs]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldAvgLatencyMs)
				fieldSeen[channelperformance.FieldAvgLatencyMs] = struct{}{}
			}
		case "avgTokenPerSecond":
			if _, ok := fieldSeen[channelperformance.FieldAvgTokenPerSecond]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldAvgTokenPerSecond)
				fieldSeen[channelperformance.FieldAvgTokenPerSecond] = struct{}{}
			}
		case "avgStreamFirstTokenLatencyMs":
			if _, ok := fieldSeen[channelperformance.FieldAvgStreamFirstTokenLatencyMs]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldAvgStreamFirstTokenLatencyMs)
				fieldSeen[channelperformance.FieldAvgStreamFirstTokenLatencyMs] = struct{}{}
			}
		case "avgStreamTokenPerSecond":
			if _, ok := fieldSeen[channelperformance.FieldAvgStreamTokenPerSecond]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldAvgStreamTokenPerSecond)
				fieldSeen[channelperformance.FieldAvgStreamTokenPerSecond] = struct{}{}
			}
		case "lastSuccessAt":
			if _, ok := fieldSeen[channelperformance.FieldLastSuccessAt]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldLastSuccessAt)
				fieldSeen[channelperformance.FieldLastSuccessAt] = struct{}{}
			}
		case "lastFailureAt":
			if _, ok := fieldSeen[channelperformance.FieldLastFailureAt]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldLastFailureAt)
				fieldSeen[channelperformance.FieldLastFailureAt] = struct{}{}
			}
		case "requestCount":
			if _, ok := fieldSeen[channelperformance.FieldRequestCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldRequestCount)
				fieldSeen[channelperformance.FieldRequestCount] = struct{}{}
			}
		case "successCount":
			if _, ok := fieldSeen[channelperformance.FieldSuccessCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldSuccessCount)
				fieldSeen[channelperformance.FieldSuccessCount] = struct{}{}
			}
		case "failureCount":
			if _, ok := fieldSeen[channelperformance.FieldFailureCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldFailureCount)
				fieldSeen[channelperformance.FieldFailureCount] = struct{}{}
			}
		case "totalTokenCount":
			if _, ok := fieldSeen[channelperformance.FieldTotalTokenCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldTotalTokenCount)
				fieldSeen[channelperformance.FieldTotalTokenCount] = struct{}{}
			}
		case "totalRequestLatencyMs":
			if _, ok := fieldSeen[channelperformance.FieldTotalRequestLatencyMs]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldTotalRequestLatencyMs)
				fieldSeen[channelperformance.FieldTotalRequestLatencyMs] = struct{}{}
			}
		case "streamSuccessCount":
			if _, ok := fieldSeen[channelperformance.FieldStreamSuccessCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldStreamSuccessCount)
				fieldSeen[channelperformance.FieldStreamSuccessCount] = struct{}{}
			}
		case "streamTotalRequestCount":
			if _, ok := fieldSeen[channelperformance.FieldStreamTotalRequestCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldStreamTotalRequestCount)
				fieldSeen[channelperformance.FieldStreamTotalRequestCount] = struct{}{}
			}
		case "streamTotalTokenCount":
			if _, ok := fieldSeen[channelperformance.FieldStreamTotalTokenCount]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldStreamTotalTokenCount)
				fieldSeen[channelperformance.FieldStreamTotalTokenCount] = struct{}{}
			}
		case "streamTotalRequestLatencyMs":
			if _, ok := fieldSeen[channelperformance.FieldStreamTotalRequestLatencyMs]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldStreamTotalRequestLatencyMs)
				fieldSeen[channelperformance.FieldStreamTotalRequestLatencyMs] = struct{}{}
			}
		case "streamTotalFirstTokenLatencyMs":
			if _, ok := fieldSeen[channelperformance.FieldStreamTotalFirstTokenLatencyMs]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldStreamTotalFirstTokenLatencyMs)
				fieldSeen[channelperformance.FieldStreamTotalFirstTokenLatencyMs] = struct{}{}
			}
		case "consecutiveFailures":
			if _, ok := fieldSeen[channelperformance.FieldConsecutiveFailures]; !ok {
				selectedFields = append(selectedFields, channelperformance.FieldConsecutiveFailures)
				fieldSeen[channelperformance.FieldConsecutiveFailures] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type channelperformancePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ChannelPerformancePaginateOption
}

func newChannelPerformancePaginateArgs(rv map[string]any) *channelperformancePaginateArgs {
	args := &channelperformancePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ChannelPerformanceOrder{Field: &ChannelPerformanceOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithChannelPerformanceOrder(order))
			}
		case *ChannelPerformanceOrder:
			if v != nil {
				args.opts = append(args.opts, WithChannelPerformanceOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ChannelPerformanceWhereInput); ok {
		args.opts = append(args.opts, WithChannelPerformanceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *DataStorageQuery) CollectFields(ctx context.Context, satisfies ...string) (*DataStorageQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *DataStorageQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(datastorage.Columns))
		selectedFields = []string{datastorage.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DataStorage) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"data_storage_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(datastorage.RequestsColumn), ids...))
						})
						if err := query.GroupBy(datastorage.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DataStorage) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(datastorage.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})

		case "executions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestExecutionClient{config: _q.config}).Query()
			)
			args := newRequestExecutionPaginateArgs(fieldArgs(ctx, new(RequestExecutionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestExecutionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*DataStorage) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"data_storage_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(datastorage.ExecutionsColumn), ids...))
						})
						if err := query.GroupBy(datastorage.ExecutionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*DataStorage) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Executions)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestexecutionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(datastorage.ExecutionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedExecutions(alias, func(wq *RequestExecutionQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[datastorage.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldCreatedAt)
				fieldSeen[datastorage.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[datastorage.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldUpdatedAt)
				fieldSeen[datastorage.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[datastorage.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldDeletedAt)
				fieldSeen[datastorage.FieldDeletedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[datastorage.FieldName]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldName)
				fieldSeen[datastorage.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[datastorage.FieldDescription]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldDescription)
				fieldSeen[datastorage.FieldDescription] = struct{}{}
			}
		case "primary":
			if _, ok := fieldSeen[datastorage.FieldPrimary]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldPrimary)
				fieldSeen[datastorage.FieldPrimary] = struct{}{}
			}
		case "type":
			if _, ok := fieldSeen[datastorage.FieldType]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldType)
				fieldSeen[datastorage.FieldType] = struct{}{}
			}
		case "settings":
			if _, ok := fieldSeen[datastorage.FieldSettings]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldSettings)
				fieldSeen[datastorage.FieldSettings] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[datastorage.FieldStatus]; !ok {
				selectedFields = append(selectedFields, datastorage.FieldStatus)
				fieldSeen[datastorage.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type datastoragePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []DataStoragePaginateOption
}

func newDataStoragePaginateArgs(rv map[string]any) *datastoragePaginateArgs {
	args := &datastoragePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &DataStorageOrder{Field: &DataStorageOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithDataStorageOrder(order))
			}
		case *DataStorageOrder:
			if v != nil {
				args.opts = append(args.opts, WithDataStorageOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*DataStorageWhereInput); ok {
		args.opts = append(args.opts, WithDataStorageFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ProjectQuery) CollectFields(ctx context.Context, satisfies ...string) (*ProjectQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ProjectQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(project.Columns))
		selectedFields = []string{project.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(project.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(project.UsersPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(project.UsersPrimaryKey[0]), ids...))
							s.Select(joinT.C(project.UsersPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(project.UsersPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.UsersPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "roles":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RoleClient{config: _q.config}).Query()
			)
			args := newRolePaginateArgs(fieldArgs(ctx, new(RoleWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRolePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.RolesColumn), ids...))
						})
						if err := query.GroupBy(project.RolesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Roles)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, roleImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.RolesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRoles(alias, func(wq *RoleQuery) {
				*wq = *query
			})

		case "apiKeys":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APIKeyClient{config: _q.config}).Query()
			)
			args := newAPIKeyPaginateArgs(fieldArgs(ctx, new(APIKeyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAPIKeyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.APIKeysColumn), ids...))
						})
						if err := query.GroupBy(project.APIKeysColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.APIKeys)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, apikeyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.APIKeysColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAPIKeys(alias, func(wq *APIKeyQuery) {
				*wq = *query
			})

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.RequestsColumn), ids...))
						})
						if err := query.GroupBy(project.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})

		case "usageLogs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UsageLogClient{config: _q.config}).Query()
			)
			args := newUsageLogPaginateArgs(fieldArgs(ctx, new(UsageLogWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUsageLogPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.UsageLogsColumn), ids...))
						})
						if err := query.GroupBy(project.UsageLogsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UsageLogs)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, usagelogImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.UsageLogsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsageLogs(alias, func(wq *UsageLogQuery) {
				*wq = *query
			})

		case "threads":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ThreadClient{config: _q.config}).Query()
			)
			args := newThreadPaginateArgs(fieldArgs(ctx, new(ThreadWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newThreadPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.ThreadsColumn), ids...))
						})
						if err := query.GroupBy(project.ThreadsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Threads)
							if nodes[i].Edges.totalCount[5] == nil {
								nodes[i].Edges.totalCount[5] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[5][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, threadImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.ThreadsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedThreads(alias, func(wq *ThreadQuery) {
				*wq = *query
			})

		case "traces":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TraceClient{config: _q.config}).Query()
			)
			args := newTracePaginateArgs(fieldArgs(ctx, new(TraceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTracePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.TracesColumn), ids...))
						})
						if err := query.GroupBy(project.TracesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Traces)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, traceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.TracesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTraces(alias, func(wq *TraceQuery) {
				*wq = *query
			})

		case "projectUsers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserProjectClient{config: _q.config}).Query()
			)
			args := newUserProjectPaginateArgs(fieldArgs(ctx, new(UserProjectWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserProjectPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Project) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"project_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(project.ProjectUsersColumn), ids...))
						})
						if err := query.GroupBy(project.ProjectUsersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Project) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProjectUsers)
							if nodes[i].Edges.totalCount[7] == nil {
								nodes[i].Edges.totalCount[7] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[7][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userprojectImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(project.ProjectUsersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProjectUsers(alias, func(wq *UserProjectQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[project.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, project.FieldCreatedAt)
				fieldSeen[project.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[project.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, project.FieldUpdatedAt)
				fieldSeen[project.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[project.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, project.FieldDeletedAt)
				fieldSeen[project.FieldDeletedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[project.FieldName]; !ok {
				selectedFields = append(selectedFields, project.FieldName)
				fieldSeen[project.FieldName] = struct{}{}
			}
		case "description":
			if _, ok := fieldSeen[project.FieldDescription]; !ok {
				selectedFields = append(selectedFields, project.FieldDescription)
				fieldSeen[project.FieldDescription] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[project.FieldStatus]; !ok {
				selectedFields = append(selectedFields, project.FieldStatus)
				fieldSeen[project.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type projectPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ProjectPaginateOption
}

func newProjectPaginateArgs(rv map[string]any) *projectPaginateArgs {
	args := &projectPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ProjectOrder{Field: &ProjectOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithProjectOrder(order))
			}
		case *ProjectOrder:
			if v != nil {
				args.opts = append(args.opts, WithProjectOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ProjectWhereInput); ok {
		args.opts = append(args.opts, WithProjectFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RequestQuery) CollectFields(ctx context.Context, satisfies ...string) (*RequestQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RequestQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(request.Columns))
		selectedFields = []string{request.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "apiKey":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APIKeyClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, apikeyImplementors)...); err != nil {
				return err
			}
			_q.withAPIKey = query
			if _, ok := fieldSeen[request.FieldAPIKeyID]; !ok {
				selectedFields = append(selectedFields, request.FieldAPIKeyID)
				fieldSeen[request.FieldAPIKeyID] = struct{}{}
			}

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[request.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, request.FieldProjectID)
				fieldSeen[request.FieldProjectID] = struct{}{}
			}

		case "trace":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TraceClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, traceImplementors)...); err != nil {
				return err
			}
			_q.withTrace = query
			if _, ok := fieldSeen[request.FieldTraceID]; !ok {
				selectedFields = append(selectedFields, request.FieldTraceID)
				fieldSeen[request.FieldTraceID] = struct{}{}
			}

		case "dataStorage":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DataStorageClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, datastorageImplementors)...); err != nil {
				return err
			}
			_q.withDataStorage = query
			if _, ok := fieldSeen[request.FieldDataStorageID]; !ok {
				selectedFields = append(selectedFields, request.FieldDataStorageID)
				fieldSeen[request.FieldDataStorageID] = struct{}{}
			}

		case "executions":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestExecutionClient{config: _q.config}).Query()
			)
			args := newRequestExecutionPaginateArgs(fieldArgs(ctx, new(RequestExecutionWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestExecutionPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Request) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"request_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(request.ExecutionsColumn), ids...))
						})
						if err := query.GroupBy(request.ExecutionsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Request) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Executions)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestexecutionImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(request.ExecutionsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedExecutions(alias, func(wq *RequestExecutionQuery) {
				*wq = *query
			})

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			_q.withChannel = query
			if _, ok := fieldSeen[request.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, request.FieldChannelID)
				fieldSeen[request.FieldChannelID] = struct{}{}
			}

		case "usageLogs":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UsageLogClient{config: _q.config}).Query()
			)
			args := newUsageLogPaginateArgs(fieldArgs(ctx, new(UsageLogWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUsageLogPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Request) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"request_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(request.UsageLogsColumn), ids...))
						})
						if err := query.GroupBy(request.UsageLogsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Request) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UsageLogs)
							if nodes[i].Edges.totalCount[6] == nil {
								nodes[i].Edges.totalCount[6] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[6][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, usagelogImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(request.UsageLogsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsageLogs(alias, func(wq *UsageLogQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[request.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, request.FieldCreatedAt)
				fieldSeen[request.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[request.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, request.FieldUpdatedAt)
				fieldSeen[request.FieldUpdatedAt] = struct{}{}
			}
		case "apiKeyID":
			if _, ok := fieldSeen[request.FieldAPIKeyID]; !ok {
				selectedFields = append(selectedFields, request.FieldAPIKeyID)
				fieldSeen[request.FieldAPIKeyID] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[request.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, request.FieldProjectID)
				fieldSeen[request.FieldProjectID] = struct{}{}
			}
		case "traceID":
			if _, ok := fieldSeen[request.FieldTraceID]; !ok {
				selectedFields = append(selectedFields, request.FieldTraceID)
				fieldSeen[request.FieldTraceID] = struct{}{}
			}
		case "dataStorageID":
			if _, ok := fieldSeen[request.FieldDataStorageID]; !ok {
				selectedFields = append(selectedFields, request.FieldDataStorageID)
				fieldSeen[request.FieldDataStorageID] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[request.FieldSource]; !ok {
				selectedFields = append(selectedFields, request.FieldSource)
				fieldSeen[request.FieldSource] = struct{}{}
			}
		case "modelID":
			if _, ok := fieldSeen[request.FieldModelID]; !ok {
				selectedFields = append(selectedFields, request.FieldModelID)
				fieldSeen[request.FieldModelID] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[request.FieldFormat]; !ok {
				selectedFields = append(selectedFields, request.FieldFormat)
				fieldSeen[request.FieldFormat] = struct{}{}
			}
		case "requestBody":
			if _, ok := fieldSeen[request.FieldRequestBody]; !ok {
				selectedFields = append(selectedFields, request.FieldRequestBody)
				fieldSeen[request.FieldRequestBody] = struct{}{}
			}
		case "responseBody":
			if _, ok := fieldSeen[request.FieldResponseBody]; !ok {
				selectedFields = append(selectedFields, request.FieldResponseBody)
				fieldSeen[request.FieldResponseBody] = struct{}{}
			}
		case "responseChunks":
			if _, ok := fieldSeen[request.FieldResponseChunks]; !ok {
				selectedFields = append(selectedFields, request.FieldResponseChunks)
				fieldSeen[request.FieldResponseChunks] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[request.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, request.FieldChannelID)
				fieldSeen[request.FieldChannelID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[request.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, request.FieldExternalID)
				fieldSeen[request.FieldExternalID] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[request.FieldStatus]; !ok {
				selectedFields = append(selectedFields, request.FieldStatus)
				fieldSeen[request.FieldStatus] = struct{}{}
			}
		case "stream":
			if _, ok := fieldSeen[request.FieldStream]; !ok {
				selectedFields = append(selectedFields, request.FieldStream)
				fieldSeen[request.FieldStream] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type requestPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RequestPaginateOption
}

func newRequestPaginateArgs(rv map[string]any) *requestPaginateArgs {
	args := &requestPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RequestOrder{Field: &RequestOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRequestOrder(order))
			}
		case *RequestOrder:
			if v != nil {
				args.opts = append(args.opts, WithRequestOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RequestWhereInput); ok {
		args.opts = append(args.opts, WithRequestFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RequestExecutionQuery) CollectFields(ctx context.Context, satisfies ...string) (*RequestExecutionQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RequestExecutionQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(requestexecution.Columns))
		selectedFields = []string{requestexecution.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "request":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
				return err
			}
			_q.withRequest = query
			if _, ok := fieldSeen[requestexecution.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldRequestID)
				fieldSeen[requestexecution.FieldRequestID] = struct{}{}
			}

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			_q.withChannel = query
			if _, ok := fieldSeen[requestexecution.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldChannelID)
				fieldSeen[requestexecution.FieldChannelID] = struct{}{}
			}

		case "dataStorage":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&DataStorageClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, datastorageImplementors)...); err != nil {
				return err
			}
			_q.withDataStorage = query
			if _, ok := fieldSeen[requestexecution.FieldDataStorageID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldDataStorageID)
				fieldSeen[requestexecution.FieldDataStorageID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[requestexecution.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldCreatedAt)
				fieldSeen[requestexecution.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[requestexecution.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldUpdatedAt)
				fieldSeen[requestexecution.FieldUpdatedAt] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[requestexecution.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldProjectID)
				fieldSeen[requestexecution.FieldProjectID] = struct{}{}
			}
		case "requestID":
			if _, ok := fieldSeen[requestexecution.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldRequestID)
				fieldSeen[requestexecution.FieldRequestID] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[requestexecution.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldChannelID)
				fieldSeen[requestexecution.FieldChannelID] = struct{}{}
			}
		case "dataStorageID":
			if _, ok := fieldSeen[requestexecution.FieldDataStorageID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldDataStorageID)
				fieldSeen[requestexecution.FieldDataStorageID] = struct{}{}
			}
		case "externalID":
			if _, ok := fieldSeen[requestexecution.FieldExternalID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldExternalID)
				fieldSeen[requestexecution.FieldExternalID] = struct{}{}
			}
		case "modelID":
			if _, ok := fieldSeen[requestexecution.FieldModelID]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldModelID)
				fieldSeen[requestexecution.FieldModelID] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[requestexecution.FieldFormat]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldFormat)
				fieldSeen[requestexecution.FieldFormat] = struct{}{}
			}
		case "requestBody":
			if _, ok := fieldSeen[requestexecution.FieldRequestBody]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldRequestBody)
				fieldSeen[requestexecution.FieldRequestBody] = struct{}{}
			}
		case "responseBody":
			if _, ok := fieldSeen[requestexecution.FieldResponseBody]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldResponseBody)
				fieldSeen[requestexecution.FieldResponseBody] = struct{}{}
			}
		case "responseChunks":
			if _, ok := fieldSeen[requestexecution.FieldResponseChunks]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldResponseChunks)
				fieldSeen[requestexecution.FieldResponseChunks] = struct{}{}
			}
		case "errorMessage":
			if _, ok := fieldSeen[requestexecution.FieldErrorMessage]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldErrorMessage)
				fieldSeen[requestexecution.FieldErrorMessage] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[requestexecution.FieldStatus]; !ok {
				selectedFields = append(selectedFields, requestexecution.FieldStatus)
				fieldSeen[requestexecution.FieldStatus] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type requestexecutionPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RequestExecutionPaginateOption
}

func newRequestExecutionPaginateArgs(rv map[string]any) *requestexecutionPaginateArgs {
	args := &requestexecutionPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RequestExecutionOrder{Field: &RequestExecutionOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRequestExecutionOrder(order))
			}
		case *RequestExecutionOrder:
			if v != nil {
				args.opts = append(args.opts, WithRequestExecutionOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RequestExecutionWhereInput); ok {
		args.opts = append(args.opts, WithRequestExecutionFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *RoleQuery) CollectFields(ctx context.Context, satisfies ...string) (*RoleQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *RoleQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(role.Columns))
		selectedFields = []string{role.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "users":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			args := newUserPaginateArgs(fieldArgs(ctx, new(UserWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Role) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"role_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(role.UsersTable)
							s.Join(joinT).On(s.C(user.FieldID), joinT.C(role.UsersPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(role.UsersPrimaryKey[1]), ids...))
							s.Select(joinT.C(role.UsersPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(role.UsersPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Role) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Users)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(role.UsersPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUsers(alias, func(wq *UserQuery) {
				*wq = *query
			})

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[role.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, role.FieldProjectID)
				fieldSeen[role.FieldProjectID] = struct{}{}
			}

		case "userRoles":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserRoleClient{config: _q.config}).Query()
			)
			args := newUserRolePaginateArgs(fieldArgs(ctx, new(UserRoleWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserRolePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Role) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"role_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(role.UserRolesColumn), ids...))
						})
						if err := query.GroupBy(role.UserRolesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Role) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UserRoles)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userroleImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(role.UserRolesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUserRoles(alias, func(wq *UserRoleQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[role.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, role.FieldCreatedAt)
				fieldSeen[role.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[role.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, role.FieldUpdatedAt)
				fieldSeen[role.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[role.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, role.FieldDeletedAt)
				fieldSeen[role.FieldDeletedAt] = struct{}{}
			}
		case "name":
			if _, ok := fieldSeen[role.FieldName]; !ok {
				selectedFields = append(selectedFields, role.FieldName)
				fieldSeen[role.FieldName] = struct{}{}
			}
		case "level":
			if _, ok := fieldSeen[role.FieldLevel]; !ok {
				selectedFields = append(selectedFields, role.FieldLevel)
				fieldSeen[role.FieldLevel] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[role.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, role.FieldProjectID)
				fieldSeen[role.FieldProjectID] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[role.FieldScopes]; !ok {
				selectedFields = append(selectedFields, role.FieldScopes)
				fieldSeen[role.FieldScopes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type rolePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []RolePaginateOption
}

func newRolePaginateArgs(rv map[string]any) *rolePaginateArgs {
	args := &rolePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &RoleOrder{Field: &RoleOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithRoleOrder(order))
			}
		case *RoleOrder:
			if v != nil {
				args.opts = append(args.opts, WithRoleOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*RoleWhereInput); ok {
		args.opts = append(args.opts, WithRoleFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *SystemQuery) CollectFields(ctx context.Context, satisfies ...string) (*SystemQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *SystemQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(system.Columns))
		selectedFields = []string{system.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {
		case "createdAt":
			if _, ok := fieldSeen[system.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, system.FieldCreatedAt)
				fieldSeen[system.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[system.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, system.FieldUpdatedAt)
				fieldSeen[system.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[system.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, system.FieldDeletedAt)
				fieldSeen[system.FieldDeletedAt] = struct{}{}
			}
		case "key":
			if _, ok := fieldSeen[system.FieldKey]; !ok {
				selectedFields = append(selectedFields, system.FieldKey)
				fieldSeen[system.FieldKey] = struct{}{}
			}
		case "value":
			if _, ok := fieldSeen[system.FieldValue]; !ok {
				selectedFields = append(selectedFields, system.FieldValue)
				fieldSeen[system.FieldValue] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type systemPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []SystemPaginateOption
}

func newSystemPaginateArgs(rv map[string]any) *systemPaginateArgs {
	args := &systemPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &SystemOrder{Field: &SystemOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithSystemOrder(order))
			}
		case *SystemOrder:
			if v != nil {
				args.opts = append(args.opts, WithSystemOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*SystemWhereInput); ok {
		args.opts = append(args.opts, WithSystemFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *ThreadQuery) CollectFields(ctx context.Context, satisfies ...string) (*ThreadQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *ThreadQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(thread.Columns))
		selectedFields = []string{thread.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[thread.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, thread.FieldProjectID)
				fieldSeen[thread.FieldProjectID] = struct{}{}
			}

		case "traces":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&TraceClient{config: _q.config}).Query()
			)
			args := newTracePaginateArgs(fieldArgs(ctx, new(TraceWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newTracePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Thread) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"thread_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(thread.TracesColumn), ids...))
						})
						if err := query.GroupBy(thread.TracesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Thread) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Traces)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, traceImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(thread.TracesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedTraces(alias, func(wq *TraceQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[thread.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, thread.FieldCreatedAt)
				fieldSeen[thread.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[thread.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, thread.FieldUpdatedAt)
				fieldSeen[thread.FieldUpdatedAt] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[thread.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, thread.FieldProjectID)
				fieldSeen[thread.FieldProjectID] = struct{}{}
			}
		case "threadID":
			if _, ok := fieldSeen[thread.FieldThreadID]; !ok {
				selectedFields = append(selectedFields, thread.FieldThreadID)
				fieldSeen[thread.FieldThreadID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type threadPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []ThreadPaginateOption
}

func newThreadPaginateArgs(rv map[string]any) *threadPaginateArgs {
	args := &threadPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &ThreadOrder{Field: &ThreadOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithThreadOrder(order))
			}
		case *ThreadOrder:
			if v != nil {
				args.opts = append(args.opts, WithThreadOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*ThreadWhereInput); ok {
		args.opts = append(args.opts, WithThreadFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *TraceQuery) CollectFields(ctx context.Context, satisfies ...string) (*TraceQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *TraceQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(trace.Columns))
		selectedFields = []string{trace.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[trace.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, trace.FieldProjectID)
				fieldSeen[trace.FieldProjectID] = struct{}{}
			}

		case "thread":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ThreadClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, threadImplementors)...); err != nil {
				return err
			}
			_q.withThread = query
			if _, ok := fieldSeen[trace.FieldThreadID]; !ok {
				selectedFields = append(selectedFields, trace.FieldThreadID)
				fieldSeen[trace.FieldThreadID] = struct{}{}
			}

		case "requests":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			args := newRequestPaginateArgs(fieldArgs(ctx, new(RequestWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRequestPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*Trace) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"trace_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(trace.RequestsColumn), ids...))
						})
						if err := query.GroupBy(trace.RequestsColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*Trace) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Requests)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(trace.RequestsColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRequests(alias, func(wq *RequestQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[trace.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, trace.FieldCreatedAt)
				fieldSeen[trace.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[trace.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, trace.FieldUpdatedAt)
				fieldSeen[trace.FieldUpdatedAt] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[trace.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, trace.FieldProjectID)
				fieldSeen[trace.FieldProjectID] = struct{}{}
			}
		case "traceID":
			if _, ok := fieldSeen[trace.FieldTraceID]; !ok {
				selectedFields = append(selectedFields, trace.FieldTraceID)
				fieldSeen[trace.FieldTraceID] = struct{}{}
			}
		case "threadID":
			if _, ok := fieldSeen[trace.FieldThreadID]; !ok {
				selectedFields = append(selectedFields, trace.FieldThreadID)
				fieldSeen[trace.FieldThreadID] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type tracePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []TracePaginateOption
}

func newTracePaginateArgs(rv map[string]any) *tracePaginateArgs {
	args := &tracePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &TraceOrder{Field: &TraceOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithTraceOrder(order))
			}
		case *TraceOrder:
			if v != nil {
				args.opts = append(args.opts, WithTraceOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*TraceWhereInput); ok {
		args.opts = append(args.opts, WithTraceFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UsageLogQuery) CollectFields(ctx context.Context, satisfies ...string) (*UsageLogQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UsageLogQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(usagelog.Columns))
		selectedFields = []string{usagelog.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "request":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RequestClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, requestImplementors)...); err != nil {
				return err
			}
			_q.withRequest = query
			if _, ok := fieldSeen[usagelog.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldRequestID)
				fieldSeen[usagelog.FieldRequestID] = struct{}{}
			}

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[usagelog.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldProjectID)
				fieldSeen[usagelog.FieldProjectID] = struct{}{}
			}

		case "channel":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ChannelClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, channelImplementors)...); err != nil {
				return err
			}
			_q.withChannel = query
			if _, ok := fieldSeen[usagelog.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldChannelID)
				fieldSeen[usagelog.FieldChannelID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[usagelog.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCreatedAt)
				fieldSeen[usagelog.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[usagelog.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldUpdatedAt)
				fieldSeen[usagelog.FieldUpdatedAt] = struct{}{}
			}
		case "requestID":
			if _, ok := fieldSeen[usagelog.FieldRequestID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldRequestID)
				fieldSeen[usagelog.FieldRequestID] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[usagelog.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldProjectID)
				fieldSeen[usagelog.FieldProjectID] = struct{}{}
			}
		case "channelID":
			if _, ok := fieldSeen[usagelog.FieldChannelID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldChannelID)
				fieldSeen[usagelog.FieldChannelID] = struct{}{}
			}
		case "modelID":
			if _, ok := fieldSeen[usagelog.FieldModelID]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldModelID)
				fieldSeen[usagelog.FieldModelID] = struct{}{}
			}
		case "promptTokens":
			if _, ok := fieldSeen[usagelog.FieldPromptTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldPromptTokens)
				fieldSeen[usagelog.FieldPromptTokens] = struct{}{}
			}
		case "completionTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionTokens)
				fieldSeen[usagelog.FieldCompletionTokens] = struct{}{}
			}
		case "totalTokens":
			if _, ok := fieldSeen[usagelog.FieldTotalTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldTotalTokens)
				fieldSeen[usagelog.FieldTotalTokens] = struct{}{}
			}
		case "promptAudioTokens":
			if _, ok := fieldSeen[usagelog.FieldPromptAudioTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldPromptAudioTokens)
				fieldSeen[usagelog.FieldPromptAudioTokens] = struct{}{}
			}
		case "promptCachedTokens":
			if _, ok := fieldSeen[usagelog.FieldPromptCachedTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldPromptCachedTokens)
				fieldSeen[usagelog.FieldPromptCachedTokens] = struct{}{}
			}
		case "completionAudioTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionAudioTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionAudioTokens)
				fieldSeen[usagelog.FieldCompletionAudioTokens] = struct{}{}
			}
		case "completionReasoningTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionReasoningTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionReasoningTokens)
				fieldSeen[usagelog.FieldCompletionReasoningTokens] = struct{}{}
			}
		case "completionAcceptedPredictionTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionAcceptedPredictionTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionAcceptedPredictionTokens)
				fieldSeen[usagelog.FieldCompletionAcceptedPredictionTokens] = struct{}{}
			}
		case "completionRejectedPredictionTokens":
			if _, ok := fieldSeen[usagelog.FieldCompletionRejectedPredictionTokens]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldCompletionRejectedPredictionTokens)
				fieldSeen[usagelog.FieldCompletionRejectedPredictionTokens] = struct{}{}
			}
		case "source":
			if _, ok := fieldSeen[usagelog.FieldSource]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldSource)
				fieldSeen[usagelog.FieldSource] = struct{}{}
			}
		case "format":
			if _, ok := fieldSeen[usagelog.FieldFormat]; !ok {
				selectedFields = append(selectedFields, usagelog.FieldFormat)
				fieldSeen[usagelog.FieldFormat] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type usagelogPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UsageLogPaginateOption
}

func newUsageLogPaginateArgs(rv map[string]any) *usagelogPaginateArgs {
	args := &usagelogPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UsageLogOrder{Field: &UsageLogOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUsageLogOrder(order))
			}
		case *UsageLogOrder:
			if v != nil {
				args.opts = append(args.opts, WithUsageLogOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UsageLogWhereInput); ok {
		args.opts = append(args.opts, WithUsageLogFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(user.Columns))
		selectedFields = []string{user.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "projects":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			args := newProjectPaginateArgs(fieldArgs(ctx, new(ProjectWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newProjectPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.ProjectsTable)
							s.Join(joinT).On(s.C(project.FieldID), joinT.C(user.ProjectsPrimaryKey[0]))
							s.Where(sql.InValues(joinT.C(user.ProjectsPrimaryKey[1]), ids...))
							s.Select(joinT.C(user.ProjectsPrimaryKey[1]), sql.Count("*"))
							s.GroupBy(joinT.C(user.ProjectsPrimaryKey[1]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Projects)
							if nodes[i].Edges.totalCount[0] == nil {
								nodes[i].Edges.totalCount[0] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[0][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProjectsPrimaryKey[1], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProjects(alias, func(wq *ProjectQuery) {
				*wq = *query
			})

		case "apiKeys":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&APIKeyClient{config: _q.config}).Query()
			)
			args := newAPIKeyPaginateArgs(fieldArgs(ctx, new(APIKeyWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newAPIKeyPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.APIKeysColumn), ids...))
						})
						if err := query.GroupBy(user.APIKeysColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.APIKeys)
							if nodes[i].Edges.totalCount[1] == nil {
								nodes[i].Edges.totalCount[1] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[1][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, apikeyImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.APIKeysColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedAPIKeys(alias, func(wq *APIKeyQuery) {
				*wq = *query
			})

		case "roles":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RoleClient{config: _q.config}).Query()
			)
			args := newRolePaginateArgs(fieldArgs(ctx, new(RoleWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newRolePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							joinT := sql.Table(user.RolesTable)
							s.Join(joinT).On(s.C(role.FieldID), joinT.C(user.RolesPrimaryKey[1]))
							s.Where(sql.InValues(joinT.C(user.RolesPrimaryKey[0]), ids...))
							s.Select(joinT.C(user.RolesPrimaryKey[0]), sql.Count("*"))
							s.GroupBy(joinT.C(user.RolesPrimaryKey[0]))
						})
						if err := query.Select().Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.Roles)
							if nodes[i].Edges.totalCount[2] == nil {
								nodes[i].Edges.totalCount[2] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[2][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, roleImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.RolesPrimaryKey[0], limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedRoles(alias, func(wq *RoleQuery) {
				*wq = *query
			})

		case "projectUsers":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserProjectClient{config: _q.config}).Query()
			)
			args := newUserProjectPaginateArgs(fieldArgs(ctx, new(UserProjectWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserProjectPager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.ProjectUsersColumn), ids...))
						})
						if err := query.GroupBy(user.ProjectUsersColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.ProjectUsers)
							if nodes[i].Edges.totalCount[3] == nil {
								nodes[i].Edges.totalCount[3] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[3][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userprojectImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.ProjectUsersColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedProjectUsers(alias, func(wq *UserProjectQuery) {
				*wq = *query
			})

		case "userRoles":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserRoleClient{config: _q.config}).Query()
			)
			args := newUserRolePaginateArgs(fieldArgs(ctx, new(UserRoleWhereInput), path...))
			if err := validateFirstLast(args.first, args.last); err != nil {
				return fmt.Errorf("validate first and last in path %q: %w", path, err)
			}
			pager, err := newUserRolePager(args.opts, args.last != nil)
			if err != nil {
				return fmt.Errorf("create new pager in path %q: %w", path, err)
			}
			if query, err = pager.applyFilter(query); err != nil {
				return err
			}
			ignoredEdges := !hasCollectedField(ctx, append(path, edgesField)...)
			if hasCollectedField(ctx, append(path, totalCountField)...) || hasCollectedField(ctx, append(path, pageInfoField)...) {
				hasPagination := args.after != nil || args.first != nil || args.before != nil || args.last != nil
				if hasPagination || ignoredEdges {
					query := query.Clone()
					_q.loadTotal = append(_q.loadTotal, func(ctx context.Context, nodes []*User) error {
						ids := make([]driver.Value, len(nodes))
						for i := range nodes {
							ids[i] = nodes[i].ID
						}
						var v []struct {
							NodeID int `sql:"user_id"`
							Count  int `sql:"count"`
						}
						query.Where(func(s *sql.Selector) {
							s.Where(sql.InValues(s.C(user.UserRolesColumn), ids...))
						})
						if err := query.GroupBy(user.UserRolesColumn).Aggregate(Count()).Scan(ctx, &v); err != nil {
							return err
						}
						m := make(map[int]int, len(v))
						for i := range v {
							m[v[i].NodeID] = v[i].Count
						}
						for i := range nodes {
							n := m[nodes[i].ID]
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				} else {
					_q.loadTotal = append(_q.loadTotal, func(_ context.Context, nodes []*User) error {
						for i := range nodes {
							n := len(nodes[i].Edges.UserRoles)
							if nodes[i].Edges.totalCount[4] == nil {
								nodes[i].Edges.totalCount[4] = make(map[string]int)
							}
							nodes[i].Edges.totalCount[4][alias] = n
						}
						return nil
					})
				}
			}
			if ignoredEdges || (args.first != nil && *args.first == 0) || (args.last != nil && *args.last == 0) {
				continue
			}
			if query, err = pager.applyCursors(query, args.after, args.before); err != nil {
				return err
			}
			path = append(path, edgesField, nodeField)
			if field := collectedField(ctx, path...); field != nil {
				if err := query.collectField(ctx, false, opCtx, *field, path, mayAddCondition(satisfies, userroleImplementors)...); err != nil {
					return err
				}
			}
			if limit := paginateLimit(args.first, args.last); limit > 0 {
				if oneNode {
					pager.applyOrder(query.Limit(limit))
				} else {
					modify := entgql.LimitPerRow(user.UserRolesColumn, limit, pager.orderExpr(query))
					query.modifiers = append(query.modifiers, modify)
				}
			} else {
				query = pager.applyOrder(query)
			}
			_q.WithNamedUserRoles(alias, func(wq *UserRoleQuery) {
				*wq = *query
			})
		case "createdAt":
			if _, ok := fieldSeen[user.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldCreatedAt)
				fieldSeen[user.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[user.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldUpdatedAt)
				fieldSeen[user.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[user.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, user.FieldDeletedAt)
				fieldSeen[user.FieldDeletedAt] = struct{}{}
			}
		case "email":
			if _, ok := fieldSeen[user.FieldEmail]; !ok {
				selectedFields = append(selectedFields, user.FieldEmail)
				fieldSeen[user.FieldEmail] = struct{}{}
			}
		case "status":
			if _, ok := fieldSeen[user.FieldStatus]; !ok {
				selectedFields = append(selectedFields, user.FieldStatus)
				fieldSeen[user.FieldStatus] = struct{}{}
			}
		case "preferLanguage":
			if _, ok := fieldSeen[user.FieldPreferLanguage]; !ok {
				selectedFields = append(selectedFields, user.FieldPreferLanguage)
				fieldSeen[user.FieldPreferLanguage] = struct{}{}
			}
		case "firstName":
			if _, ok := fieldSeen[user.FieldFirstName]; !ok {
				selectedFields = append(selectedFields, user.FieldFirstName)
				fieldSeen[user.FieldFirstName] = struct{}{}
			}
		case "lastName":
			if _, ok := fieldSeen[user.FieldLastName]; !ok {
				selectedFields = append(selectedFields, user.FieldLastName)
				fieldSeen[user.FieldLastName] = struct{}{}
			}
		case "avatar":
			if _, ok := fieldSeen[user.FieldAvatar]; !ok {
				selectedFields = append(selectedFields, user.FieldAvatar)
				fieldSeen[user.FieldAvatar] = struct{}{}
			}
		case "isOwner":
			if _, ok := fieldSeen[user.FieldIsOwner]; !ok {
				selectedFields = append(selectedFields, user.FieldIsOwner)
				fieldSeen[user.FieldIsOwner] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[user.FieldScopes]; !ok {
				selectedFields = append(selectedFields, user.FieldScopes)
				fieldSeen[user.FieldScopes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type userPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserPaginateOption
}

func newUserPaginateArgs(rv map[string]any) *userPaginateArgs {
	args := &userPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserOrder{Field: &UserOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserOrder(order))
			}
		case *UserOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserWhereInput); ok {
		args.opts = append(args.opts, WithUserFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserProjectQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserProjectQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserProjectQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(userproject.Columns))
		selectedFields = []string{userproject.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[userproject.FieldUserID]; !ok {
				selectedFields = append(selectedFields, userproject.FieldUserID)
				fieldSeen[userproject.FieldUserID] = struct{}{}
			}

		case "project":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&ProjectClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, projectImplementors)...); err != nil {
				return err
			}
			_q.withProject = query
			if _, ok := fieldSeen[userproject.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, userproject.FieldProjectID)
				fieldSeen[userproject.FieldProjectID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[userproject.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, userproject.FieldCreatedAt)
				fieldSeen[userproject.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[userproject.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, userproject.FieldUpdatedAt)
				fieldSeen[userproject.FieldUpdatedAt] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[userproject.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, userproject.FieldDeletedAt)
				fieldSeen[userproject.FieldDeletedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[userproject.FieldUserID]; !ok {
				selectedFields = append(selectedFields, userproject.FieldUserID)
				fieldSeen[userproject.FieldUserID] = struct{}{}
			}
		case "projectID":
			if _, ok := fieldSeen[userproject.FieldProjectID]; !ok {
				selectedFields = append(selectedFields, userproject.FieldProjectID)
				fieldSeen[userproject.FieldProjectID] = struct{}{}
			}
		case "isOwner":
			if _, ok := fieldSeen[userproject.FieldIsOwner]; !ok {
				selectedFields = append(selectedFields, userproject.FieldIsOwner)
				fieldSeen[userproject.FieldIsOwner] = struct{}{}
			}
		case "scopes":
			if _, ok := fieldSeen[userproject.FieldScopes]; !ok {
				selectedFields = append(selectedFields, userproject.FieldScopes)
				fieldSeen[userproject.FieldScopes] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type userprojectPaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserProjectPaginateOption
}

func newUserProjectPaginateArgs(rv map[string]any) *userprojectPaginateArgs {
	args := &userprojectPaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserProjectOrder{Field: &UserProjectOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserProjectOrder(order))
			}
		case *UserProjectOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserProjectOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserProjectWhereInput); ok {
		args.opts = append(args.opts, WithUserProjectFilter(v.Filter))
	}
	return args
}

// CollectFields tells the query-builder to eagerly load connected nodes by resolver context.
func (_q *UserRoleQuery) CollectFields(ctx context.Context, satisfies ...string) (*UserRoleQuery, error) {
	fc := graphql.GetFieldContext(ctx)
	if fc == nil {
		return _q, nil
	}
	if err := _q.collectField(ctx, false, graphql.GetOperationContext(ctx), fc.Field, nil, satisfies...); err != nil {
		return nil, err
	}
	return _q, nil
}

func (_q *UserRoleQuery) collectField(ctx context.Context, oneNode bool, opCtx *graphql.OperationContext, collected graphql.CollectedField, path []string, satisfies ...string) error {
	path = append([]string(nil), path...)
	var (
		unknownSeen    bool
		fieldSeen      = make(map[string]struct{}, len(userrole.Columns))
		selectedFields = []string{userrole.FieldID}
	)
	for _, field := range graphql.CollectFields(opCtx, collected.Selections, satisfies) {
		switch field.Name {

		case "user":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&UserClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, userImplementors)...); err != nil {
				return err
			}
			_q.withUser = query
			if _, ok := fieldSeen[userrole.FieldUserID]; !ok {
				selectedFields = append(selectedFields, userrole.FieldUserID)
				fieldSeen[userrole.FieldUserID] = struct{}{}
			}

		case "role":
			var (
				alias = field.Alias
				path  = append(path, alias)
				query = (&RoleClient{config: _q.config}).Query()
			)
			if err := query.collectField(ctx, oneNode, opCtx, field, path, mayAddCondition(satisfies, roleImplementors)...); err != nil {
				return err
			}
			_q.withRole = query
			if _, ok := fieldSeen[userrole.FieldRoleID]; !ok {
				selectedFields = append(selectedFields, userrole.FieldRoleID)
				fieldSeen[userrole.FieldRoleID] = struct{}{}
			}
		case "deletedAt":
			if _, ok := fieldSeen[userrole.FieldDeletedAt]; !ok {
				selectedFields = append(selectedFields, userrole.FieldDeletedAt)
				fieldSeen[userrole.FieldDeletedAt] = struct{}{}
			}
		case "userID":
			if _, ok := fieldSeen[userrole.FieldUserID]; !ok {
				selectedFields = append(selectedFields, userrole.FieldUserID)
				fieldSeen[userrole.FieldUserID] = struct{}{}
			}
		case "roleID":
			if _, ok := fieldSeen[userrole.FieldRoleID]; !ok {
				selectedFields = append(selectedFields, userrole.FieldRoleID)
				fieldSeen[userrole.FieldRoleID] = struct{}{}
			}
		case "createdAt":
			if _, ok := fieldSeen[userrole.FieldCreatedAt]; !ok {
				selectedFields = append(selectedFields, userrole.FieldCreatedAt)
				fieldSeen[userrole.FieldCreatedAt] = struct{}{}
			}
		case "updatedAt":
			if _, ok := fieldSeen[userrole.FieldUpdatedAt]; !ok {
				selectedFields = append(selectedFields, userrole.FieldUpdatedAt)
				fieldSeen[userrole.FieldUpdatedAt] = struct{}{}
			}
		case "id":
		case "__typename":
		default:
			unknownSeen = true
		}
	}
	if !unknownSeen {
		_q.Select(selectedFields...)
	}
	return nil
}

type userrolePaginateArgs struct {
	first, last   *int
	after, before *Cursor
	opts          []UserRolePaginateOption
}

func newUserRolePaginateArgs(rv map[string]any) *userrolePaginateArgs {
	args := &userrolePaginateArgs{}
	if rv == nil {
		return args
	}
	if v := rv[firstField]; v != nil {
		args.first = v.(*int)
	}
	if v := rv[lastField]; v != nil {
		args.last = v.(*int)
	}
	if v := rv[afterField]; v != nil {
		args.after = v.(*Cursor)
	}
	if v := rv[beforeField]; v != nil {
		args.before = v.(*Cursor)
	}
	if v, ok := rv[orderByField]; ok {
		switch v := v.(type) {
		case map[string]any:
			var (
				err1, err2 error
				order      = &UserRoleOrder{Field: &UserRoleOrderField{}, Direction: entgql.OrderDirectionAsc}
			)
			if d, ok := v[directionField]; ok {
				err1 = order.Direction.UnmarshalGQL(d)
			}
			if f, ok := v[fieldField]; ok {
				err2 = order.Field.UnmarshalGQL(f)
			}
			if err1 == nil && err2 == nil {
				args.opts = append(args.opts, WithUserRoleOrder(order))
			}
		case *UserRoleOrder:
			if v != nil {
				args.opts = append(args.opts, WithUserRoleOrder(v))
			}
		}
	}
	if v, ok := rv[whereField].(*UserRoleWhereInput); ok {
		args.opts = append(args.opts, WithUserRoleFilter(v.Filter))
	}
	return args
}

const (
	afterField     = "after"
	firstField     = "first"
	beforeField    = "before"
	lastField      = "last"
	orderByField   = "orderBy"
	directionField = "direction"
	fieldField     = "field"
	whereField     = "where"
)

func fieldArgs(ctx context.Context, whereInput any, path ...string) map[string]any {
	field := collectedField(ctx, path...)
	if field == nil || field.Arguments == nil {
		return nil
	}
	oc := graphql.GetOperationContext(ctx)
	args := field.ArgumentMap(oc.Variables)
	return unmarshalArgs(ctx, whereInput, args)
}

// unmarshalArgs allows extracting the field arguments from their raw representation.
func unmarshalArgs(ctx context.Context, whereInput any, args map[string]any) map[string]any {
	for _, k := range []string{firstField, lastField} {
		v, ok := args[k]
		if !ok || v == nil {
			continue
		}
		i, err := graphql.UnmarshalInt(v)
		if err == nil {
			args[k] = &i
		}
	}
	for _, k := range []string{beforeField, afterField} {
		v, ok := args[k]
		if !ok {
			continue
		}
		c := &Cursor{}
		if c.UnmarshalGQL(v) == nil {
			args[k] = c
		}
	}
	if v, ok := args[whereField]; ok && whereInput != nil {
		if err := graphql.UnmarshalInputFromContext(ctx, v, whereInput); err == nil {
			args[whereField] = whereInput
		}
	}

	return args
}

// mayAddCondition appends another type condition to the satisfies list
// if it does not exist in the list.
func mayAddCondition(satisfies []string, typeCond []string) []string {
Cond:
	for _, c := range typeCond {
		for _, s := range satisfies {
			if c == s {
				continue Cond
			}
		}
		satisfies = append(satisfies, c)
	}
	return satisfies
}
