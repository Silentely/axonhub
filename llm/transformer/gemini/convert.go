package gemini

import (
	"strings"

	"github.com/samber/lo"

	"github.com/looplj/axonhub/llm"
	"github.com/looplj/axonhub/llm/internal/pkg/xurl"
)

func extractTextFromContent(content *Content) string {
	if content == nil || len(content.Parts) == 0 {
		return ""
	}

	var texts []string

	for _, part := range content.Parts {
		if part.Text != "" && !part.Thought {
			texts = append(texts, part.Text)
		}
	}

	return strings.Join(texts, "\n")
}

func extractPartsFromLLMMessage(msg *llm.Message) []*Part {
	if msg.Content.Content != nil && *msg.Content.Content != "" {
		return []*Part{{Text: *msg.Content.Content}}
	}

	var parts []*Part

	for _, part := range msg.Content.MultipleContent {
		if part.Type == "text" && part.Text != nil && *part.Text != "" {
			parts = append(parts, &Part{Text: *part.Text})
		}
	}

	return parts
}

func convertGeminiRoleToLLMRole(role string) string {
	switch role {
	case "model":
		return "assistant"
	case "user":
		return "user"
	case "":
		return "user"
	default:
		return role
	}
}

func convertLLMRoleToGeminiRole(role string) string {
	switch role {
	case "assistant":
		return "model"
	case "user":
		return "user"
	case "developer":
		// Developer role is treated as system-equivalent and handled in system instruction
		// Convert to user for any content that needs to be processed as regular content
		return "user"
	default:
		return role
	}
}

// Defines the reason why the model stopped generating tokens.

// Enums
// FINISH_REASON_UNSPECIFIED	Default value. This value is unused.
// STOP	Natural stop point of the model or provided stop sequence.
// MAX_TOKENS	The maximum number of tokens as specified in the request was reached.
// SAFETY	The response candidate content was flagged for safety reasons.
// RECITATION	The response candidate content was flagged for recitation reasons.
// LANGUAGE	The response candidate content was flagged for using an unsupported language.
// OTHER	Unknown reason.
// BLOCKLIST	Token generation stopped because the content contains forbidden terms.
// PROHIBITED_CONTENT	Token generation stopped for potentially containing prohibited content.
// SPII	Token generation stopped because the content potentially contains Sensitive Personally Identifiable Information (SPII).
// MALFORMED_FUNCTION_CALL	The function call generated by the model is invalid.
// IMAGE_SAFETY	Token generation stopped because generated images contain safety violations.
// IMAGE_PROHIBITED_CONTENT	Image generation stopped because generated images has other prohibited content.
// IMAGE_OTHER	Image generation stopped because of other miscellaneous issue.
// NO_IMAGE	The model was expected to generate an image, but none was generated.
// IMAGE_RECITATION	Image generation stopped due to recitation.
// UNEXPECTED_TOOL_CALL	Model generated a tool call but no tools were enabled in the request.
// TOO_MANY_TOOL_CALLS	Model called too many tools consecutively, thus the system exited execution.
// MISSING_THOUGHT_SIGNATURE	Request has at least one thought signature missing.
func convertGeminiFinishReasonToLLM(reason string, hasToolCall bool) *string {
	var llmReason string

	if reason == "" {
		return nil
	}

	switch reason {
	case "STOP":
		llmReason = "stop"
		if hasToolCall {
			llmReason = "tool_calls"
		}
	case "MAX_TOKENS":
		llmReason = "length"
	case "SAFETY":
		llmReason = "content_filter"
	case "RECITATION":
		llmReason = "content_filter"
	default:
		llmReason = "stop"
	}

	return lo.ToPtr(llmReason)
}

func convertLLMFinishReasonToGemini(reason *string) string {
	if reason == nil {
		return ""
	}

	switch *reason {
	case "stop":
		return "STOP"
	case "length":
		return "MAX_TOKENS"
	case "content_filter":
		return "SAFETY"
	case "tool_calls":
		return "STOP"
	default:
		return "STOP"
	}
}

func convertImageURLToGeminiPart(url string) *Part {
	if parsed := xurl.ParseDataURL(url); parsed != nil {
		return &Part{
			InlineData: &Blob{
				MIMEType: parsed.MediaType,
				Data:     parsed.Data,
			},
		}
	}

	// Regular URL - use FileData with MIME type detection
	part := &Part{
		FileData: &FileData{
			FileURI: url,
		},
	}

	return part
}

// convertDocumentURLToGeminiPart converts a DocumentURL to a Gemini Part.
// Handles both data URLs and regular URLs for documents (PDF, Word, etc.)
func convertDocumentURLToGeminiPart(doc *llm.DocumentURL) *Part {
	if doc == nil || doc.URL == "" {
		return nil
	}

	if parsed := xurl.ParseDataURL(doc.URL); parsed != nil {
		// Data URL - use InlineData
		mimeType := parsed.MediaType
		if mimeType == "" && doc.MIMEType != "" {
			mimeType = doc.MIMEType
		}

		return &Part{
			InlineData: &Blob{
				MIMEType: mimeType,
				Data:     parsed.Data,
			},
		}
	}

	// Regular URL - use FileData
	mimeType := doc.MIMEType

	return &Part{
		FileData: &FileData{
			FileURI:  doc.URL,
			MIMEType: mimeType,
		},
	}
}

// isDocumentMIMEType checks if the MIME type represents a document (not an image).
func isDocumentMIMEType(mimeType string) bool {
	if mimeType == "" {
		return false
	}

	mimeType = strings.ToLower(mimeType)

	// Document MIME types
	return strings.HasPrefix(mimeType, "application/pdf") ||
		strings.HasPrefix(mimeType, "application/msword") ||
		strings.HasPrefix(mimeType, "application/vnd.openxmlformats-officedocument") ||
		strings.HasPrefix(mimeType, "application/vnd.ms-") ||
		strings.HasPrefix(mimeType, "text/")
}

func convertGeminiFunctionCallingConfigToToolChoice(fcc *FunctionCallingConfig) *llm.ToolChoice {
	if fcc == nil {
		return nil
	}

	tc := &llm.ToolChoice{}

	switch fcc.Mode {
	case "AUTO":
		tc.ToolChoice = lo.ToPtr("auto")
	case "ANY":
		if len(fcc.AllowedFunctionNames) == 1 {
			tc.NamedToolChoice = &llm.NamedToolChoice{
				Type: "function",
				Function: llm.ToolFunction{
					Name: fcc.AllowedFunctionNames[0],
				},
			}
		} else {
			tc.ToolChoice = lo.ToPtr("required")
		}
	case "NONE":
		tc.ToolChoice = lo.ToPtr("none")
	default:
		tc.ToolChoice = lo.ToPtr("auto")
	}

	return tc
}

func convertLLMToolChoiceToGeminiToolConfig(tc *llm.ToolChoice) *ToolConfig {
	if tc == nil {
		return nil
	}

	fcc := &FunctionCallingConfig{}

	// Check if it's a string tool choice
	if tc.ToolChoice != nil {
		switch *tc.ToolChoice {
		case "auto":
			fcc.Mode = "AUTO"
		case "none":
			fcc.Mode = "NONE"
		case "required":
			fcc.Mode = "ANY"
		default:
			fcc.Mode = "AUTO"
		}
	} else if tc.NamedToolChoice != nil {
		// Named tool choice - specific function
		fcc.Mode = "ANY"
		if tc.NamedToolChoice.Function.Name != "" {
			fcc.AllowedFunctionNames = []string{tc.NamedToolChoice.Function.Name}
		}
	} else {
		fcc.Mode = "AUTO"
	}

	return &ToolConfig{FunctionCallingConfig: fcc}
}

func thinkingBudgetToReasoningEffort(budget int64) string {
	switch {
	case budget <= 1024:
		return "low"
	case budget <= 8192:
		return "medium"
	default:
		return "high"
	}
}

// shouldUseThinkingLevelForBudget returns true if the model is Gemini 3
// and the budget falls within standard effort ranges, allowing use of
// thinkingLevel instead of thinkingBudget. Gemini 3 prefers thinkingLevel.
func shouldUseThinkingLevelForBudget(model string, budget int64) bool {
	if !strings.Contains(strings.ToLower(model), "gemini-3-") {
		return false
	}

	switch {
	case budget <= 1024:
		return true
	case budget <= 8192:
		return true
	case budget >= 1024 && budget <= 32768:
		return true
	default:
		return false
	}
}

// defaultReasoningEffortMapping returns the default mapping from ReasoningEffort to thinking budget tokens.
var defaultGeminiReasoningEffortMapping = map[string]int64{
	"low":    1024,
	"medium": 8192,
	"high":   32768,
}

func reasoningEffortToThinkingBudget(effort string) int64 {
	return reasoningEffortToThinkingBudgetWithConfig(effort, nil)
}

// reasoningEffortToThinkingBudgetWithConfig returns the thinking budget tokens for a given reasoning effort with config.
func reasoningEffortToThinkingBudgetWithConfig(effort string, config *Config) int64 {
	if config != nil && config.ReasoningEffortToBudget != nil {
		if budget, exists := config.ReasoningEffortToBudget[effort]; exists {
			return budget
		}
	}

	// Fall back to default mapping
	if budget, exists := defaultGeminiReasoningEffortMapping[effort]; exists {
		return budget
	}

	// Default to medium if not found
	return 8192
}

// convertToLLMUsage converts Gemini UsageMetadata to unified Usage format.
func convertToLLMUsage(geminiUsage *UsageMetadata) *llm.Usage {
	if geminiUsage == nil {
		return nil
	}

	usage := &llm.Usage{
		PromptTokens:     geminiUsage.PromptTokenCount,
		CompletionTokens: geminiUsage.CandidatesTokenCount + geminiUsage.ThoughtsTokenCount,
		TotalTokens:      geminiUsage.TotalTokenCount,
	}

	// Map cached tokens if present
	if geminiUsage.CachedContentTokenCount > 0 {
		usage.PromptTokensDetails = &llm.PromptTokensDetails{
			CachedTokens: geminiUsage.CachedContentTokenCount,
		}
	}

	// Map thoughts tokens if present
	if geminiUsage.ThoughtsTokenCount > 0 {
		usage.CompletionTokensDetails = &llm.CompletionTokensDetails{
			ReasoningTokens: geminiUsage.ThoughtsTokenCount,
		}
	}

	if len(geminiUsage.CandidatesTokensDetails) > 0 {
		usage.CompletionModalityTokenDetails = lo.Map(geminiUsage.CandidatesTokensDetails, func(candidate *ModalityTokenCount, _ int) llm.ModalityTokenCount {
			return llm.ModalityTokenCount{
				Modality:   candidate.Modality,
				TokenCount: candidate.TokenCount,
			}
		})
	}

	if len(geminiUsage.PromptTokensDetails) > 0 {
		usage.PromptModalityTokenDetails = lo.Map(geminiUsage.PromptTokensDetails, func(prompt *ModalityTokenCount, _ int) llm.ModalityTokenCount {
			return llm.ModalityTokenCount{
				Modality:   prompt.Modality,
				TokenCount: prompt.TokenCount,
			}
		})
	}

	return usage
}

// convertLLMModalitiesToGemini converts LLM modalities to Gemini responseModalities.
// LLM uses lowercase: "text", "image", "audio"
// Gemini uses uppercase: "TEXT", "IMAGE", "AUDIO".
func convertLLMModalitiesToGemini(modalities []string) []string {
	return lo.Map(modalities, func(m string, _ int) string {
		return strings.ToUpper(m)
	})
}

// convertGeminiModalitiesToLLM converts Gemini responseModalities to LLM modalities.
// Gemini uses uppercase: "TEXT", "IMAGE", "AUDIO"
// LLM uses lowercase: "text", "image", "audio".
func convertGeminiModalitiesToLLM(modalities []string) []string {
	return lo.Map(modalities, func(m string, _ int) string {
		return strings.ToLower(m)
	})
}

func convertToGeminiUsage(chatUsage *llm.Usage) *UsageMetadata {
	if chatUsage == nil {
		return nil
	}

	usage := &UsageMetadata{
		PromptTokenCount:        chatUsage.PromptTokens,
		CandidatesTokenCount:    chatUsage.CompletionTokens,
		TotalTokenCount:         chatUsage.TotalTokens,
		CachedContentTokenCount: 0,
		ThoughtsTokenCount:      0,
		CandidatesTokensDetails: nil,
	}

	if chatUsage.PromptTokensDetails != nil {
		usage.CachedContentTokenCount = chatUsage.PromptTokensDetails.CachedTokens
	}

	if chatUsage.CompletionTokensDetails != nil {
		usage.ThoughtsTokenCount = chatUsage.CompletionTokensDetails.ReasoningTokens
		usage.CandidatesTokenCount = chatUsage.CompletionTokens - usage.ThoughtsTokenCount
	}

	if len(chatUsage.CompletionModalityTokenDetails) > 0 {
		usage.CandidatesTokensDetails = lo.Map(chatUsage.CompletionModalityTokenDetails, func(modalityToken llm.ModalityTokenCount, _ int) *ModalityTokenCount {
			return &ModalityTokenCount{
				Modality:   modalityToken.Modality,
				TokenCount: modalityToken.TokenCount,
			}
		})
	}

	if len(chatUsage.PromptModalityTokenDetails) > 0 {
		usage.PromptTokensDetails = lo.Map(chatUsage.PromptModalityTokenDetails, func(modalityToken llm.ModalityTokenCount, _ int) *ModalityTokenCount {
			return &ModalityTokenCount{
				Modality:   modalityToken.Modality,
				TokenCount: modalityToken.TokenCount,
			}
		})
	}

	return usage
}

// TransformerMetadataKeySafetySettings is the key for storing SafetySettings in TransformerMetadata.
const TransformerMetadataKeySafetySettings = "gemini_safety_settings"

// extractSafetySettingsFromMetadata extracts SafetySettings from TransformerMetadata.
func extractSafetySettingsFromMetadata(metadata map[string]any) []*SafetySetting {
	if metadata == nil {
		return nil
	}

	if rawSettings, ok := metadata[TransformerMetadataKeySafetySettings]; ok {
		if settings, ok := rawSettings.([]*SafetySetting); ok && len(settings) > 0 {
			return settings
		}
	}

	return nil
}

// TransformerMetadataKeyImageConfig is the key for storing ImageConfig in TransformerMetadata.
const TransformerMetadataKeyImageConfig = "gemini_image_config"

// extractImageConfigFromMetadata extracts ImageConfig from TransformerMetadata.
func extractImageConfigFromMetadata(metadata map[string]any) *ImageConfig {
	if metadata == nil {
		return nil
	}

	if rawConfig, ok := metadata[TransformerMetadataKeyImageConfig]; ok {
		if config, ok := rawConfig.(*ImageConfig); ok {
			return config
		}
	}

	return nil
}
