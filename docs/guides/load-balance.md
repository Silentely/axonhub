# Adaptive Load Balancing Guide

AxonHub provides an intelligent adaptive load balancing system that automatically selects optimal AI channels based on multiple dimensions, ensuring high availability and optimal performance.

## ğŸ¯ Core Features

### Intelligent Channel Selection
- **Session Consistency** - Requests from the same conversation are prioritized to route to previously successful channels
- **Health Awareness** - Automatically avoids channels with high error rates
- **Weight Balancing** - Supports admin-configured channel priorities
- **Real-time Load** - Dynamically adjusts based on current connection count

### Multi-Strategy Scoring System
Each channel is scored by multiple strategies, with the highest-scoring channel getting priority:

| Strategy | Score Range | Description |
|----------|-------------|-------------|
| **Trace Aware** | 0-1000 points | Same session priority, ensures conversation continuity |
| **Error Aware** | 0-200 points | Based on success rate and error history |
| **Weight Strategy** | 0-100 points | Admin-configured channel weights |
| **Connection Load** | 0-50 points | Current connection utilization |

## ğŸš€ Quick Start

### 1. Configure Multiple Channels
Add multiple channels for the same model in the management interface:

```yaml
# Channel A - Primary channel
name: "openai-primary"
type: "openai"
weight: 100  # High priority
base_url: "https://api.openai.com/v1"

# Channel B - Backup channel  
name: "openai-backup"
type: "openai"
weight: 50   # Medium priority
base_url: "https://api.openai.com/v1"

# Channel C - Third-party channel
name: "azure-openai"
type: "azure"
weight: 30   # Low priority
base_url: "https://your-resource.openai.azure.com"
```

### 2. Enable Load Balancing
Load balancing is automatically enabled, no additional configuration needed. The system will:

- Automatically detect channel health status
- Sort channels based on strategy scores
- Intelligently select the optimal channel
- Automatically switch to the next channel on failure

### 3. Send Requests
Use standard OpenAI API format:

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-axonhub-api-key",
    base_url="http://localhost:8090/v1"
)

# System will automatically select the optimal channel
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

## ğŸ“Š Load Balancing Strategy Details

### Trace Aware Strategy
- **Purpose**: Maintain channel consistency for multi-turn conversations
- **Mechanism**: If request contains trace ID, prioritize previously successful channel
- **Advantage**: Avoids initialization delays from channel switching
- **Scoring**: Matching channel gets 1000 points, otherwise 0 points

### Error Aware Strategy
- **Purpose**: Avoid unhealthy channels
- **Scoring Factors**:
  - Consecutive failures: -50 points per failure
  - Recent failure (within 5 min): up to -100 points
  - Success rate >90%: +30 points
  - Success rate <50%: -50 points
- **Recovery**: Failed channels automatically recover priority over time

### Weight Strategy
- **Purpose**: Respect admin-configured channel priorities
- **Scoring**: `channel_weight / 100 * 100`
- **Range**: 0-100 points

### Connection Strategy
- **Purpose**: Prevent individual channel overload
- **Scoring**: Based on current connection utilization
- **Mechanism**: Lower utilization = higher score

## ğŸ”§ Advanced Configuration

### Enable Debug Mode
View detailed load balancing decision process:

```bash
# Set environment variable
export AXONHUB_LOAD_BALANCER_DEBUG=true

# Or enable in request
curl -X POST http://localhost:8090/v1/chat/completions \
  -H "X-Debug-Mode: true" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello"}]}'
```

### View Decision Logs
```bash
# View load balancing decisions
tail -f axonhub.log | grep "Load balancing decision"

# View specific channel scoring
tail -f axonhub.log | grep "Channel load balancing details"

# Use jq to format JSON logs
tail -f axonhub.log | jq 'select(.msg | contains("Load balancing"))'
```

## ğŸ“ˆ Monitoring and Troubleshooting

### Key Metrics
- **Channel switching frequency** - Should be relatively low under normal conditions
- **Error rate distribution** - High error rate on a channel may indicate configuration issues
- **Response time** - Load balancing should optimize overall response time

### Common Issues

**Q: Why do requests always route to the same channel?**
A: Check if session consistency is enabled. Requests with the same trace ID will prioritize the same channel.

**Q: What to do if channels don't switch?**
A: Check Error Aware strategy scoring. The channel may still be healthy or needs time to recover.

**Q: How to verify load balancing is working?**
A: Enable debug mode and view channel scoring and sorting in logs.

## ğŸ›ï¸ Best Practices

### 1. Channel Configuration
- Set different weight values to reflect priorities
- Configure multiple different provider channels for higher availability
- Regularly check channel health status

### 2. Monitoring Setup
- Monitor error rates and response times for each channel
- Set alerts when a channel continuously fails
- Regularly analyze load balancing decision logs

### 3. Performance Optimization
- Set higher weights for geographically closer channels
- Adjust channel priorities based on cost considerations
- Use session consistency to improve user experience

## ğŸ”— Related Documentation

- [Unified API Documentation](../api-reference/unified-api.md)
- [Channel Management Guide](../getting-started/quick-start.md)
- [Tracing and Debugging](tracing.md)

# è‡ªé€‚åº”è´Ÿè½½å‡è¡¡æŒ‡å—

AxonHub æä¾›æ™ºèƒ½çš„è‡ªé€‚åº”è´Ÿè½½å‡è¡¡ç³»ç»Ÿï¼Œèƒ½å¤Ÿæ ¹æ®å¤šä¸ªç»´åº¦è‡ªåŠ¨é€‰æ‹©æœ€ä¼˜çš„ AI é€šé“ï¼Œç¡®ä¿é«˜å¯ç”¨æ€§å’Œæœ€ä½³æ€§èƒ½ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

### æ™ºèƒ½é€šé“é€‰æ‹©
- **ä¼šè¯ä¸€è‡´æ€§** - åŒä¸€å¯¹è¯çš„è¯·æ±‚ä¼˜å…ˆè·¯ç”±åˆ°ä¹‹å‰æˆåŠŸçš„é€šé“
- **å¥åº·çŠ¶æ€æ„ŸçŸ¥** - è‡ªåŠ¨é¿å¼€é”™è¯¯ç‡é«˜çš„é€šé“
- **æƒé‡å‡è¡¡** - æ”¯æŒç®¡ç†å‘˜è®¾ç½®é€šé“ä¼˜å…ˆçº§
- **å®æ—¶è´Ÿè½½** - æ ¹æ®å½“å‰è¿æ¥æ•°åŠ¨æ€è°ƒæ•´

### å¤šç­–ç•¥è¯„åˆ†ç³»ç»Ÿ
æ¯ä¸ªé€šé“éƒ½ä¼šè¢«å¤šä¸ªç­–ç•¥è¯„åˆ†ï¼Œæ€»åˆ†æœ€é«˜çš„é€šé“ä¼˜å…ˆä½¿ç”¨ï¼š

| ç­–ç•¥ | è¯„åˆ†èŒƒå›´ | è¯´æ˜ |
|------|----------|------|
| **ä¼šè¯æ„ŸçŸ¥** | 0-1000 åˆ† | åŒä¸€ä¼šè¯ä¼˜å…ˆï¼Œç¡®ä¿å¯¹è¯è¿ç»­æ€§ |
| **é”™è¯¯æ„ŸçŸ¥** | 0-200 åˆ† | åŸºäºæˆåŠŸç‡å’Œé”™è¯¯å†å² |
| **æƒé‡ç­–ç•¥** | 0-100 åˆ† | ç®¡ç†å‘˜è®¾ç½®çš„é€šé“æƒé‡ |
| **è¿æ¥è´Ÿè½½** | 0-50 åˆ† | å½“å‰è¿æ¥ä½¿ç”¨ç‡ |

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. é…ç½®å¤šä¸ªé€šé“
åœ¨ç®¡ç†ç•Œé¢ä¸­æ·»åŠ å¤šä¸ªç›¸åŒæ¨¡å‹çš„é€šé“ï¼š

```yaml
# é€šé“ A - ä¸»åŠ›é€šé“
name: "openai-primary"
type: "openai"
weight: 100  # é«˜ä¼˜å…ˆçº§
base_url: "https://api.openai.com/v1"

# é€šé“ B - å¤‡ç”¨é€šé“  
name: "openai-backup"
type: "openai"
weight: 50   # ä¸­ç­‰ä¼˜å…ˆçº§
base_url: "https://api.openai.com/v1"

# é€šé“ C - ç¬¬ä¸‰æ–¹é€šé“
name: "azure-openai"
type: "azure"
weight: 30   # ä½ä¼˜å…ˆçº§
base_url: "https://your-resource.openai.azure.com"
```

### 2. å¯ç”¨è´Ÿè½½å‡è¡¡
è´Ÿè½½å‡è¡¡è‡ªåŠ¨å¯ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚ç³»ç»Ÿä¼šï¼š

- è‡ªåŠ¨æ£€æµ‹é€šé“å¥åº·çŠ¶æ€
- æ ¹æ®ç­–ç•¥è¯„åˆ†æ’åºé€šé“
- æ™ºèƒ½é€‰æ‹©æœ€ä¼˜é€šé“
- å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªé€šé“

### 3. å‘é€è¯·æ±‚
ä½¿ç”¨æ ‡å‡†çš„ OpenAI API æ ¼å¼ï¼š

```python
from openai import OpenAI

client = OpenAI(
    api_key="your-axonhub-api-key",
    base_url="http://localhost:8090/v1"
)

# ç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜é€šé“
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello!"}]
)
```

## ğŸ“Š è´Ÿè½½å‡è¡¡ç­–ç•¥è¯¦è§£

### ä¼šè¯æ„ŸçŸ¥ç­–ç•¥ (TraceAware)
- **ç›®çš„**: ä¿æŒå¤šè½®å¯¹è¯çš„é€šé“ä¸€è‡´æ€§
- **æœºåˆ¶**: å¦‚æœè¯·æ±‚åŒ…å« trace IDï¼Œä¼˜å…ˆä½¿ç”¨ä¹‹å‰æˆåŠŸçš„é€šé“
- **ä¼˜åŠ¿**: é¿å…é€šé“åˆ‡æ¢å¯¼è‡´çš„åˆå§‹åŒ–å»¶è¿Ÿ
- **è¯„åˆ†**: åŒ¹é…é€šé“è·å¾— 1000 åˆ†ï¼Œå¦åˆ™ 0 åˆ†

### é”™è¯¯æ„ŸçŸ¥ç­–ç•¥ (ErrorAware)
- **ç›®çš„**: é¿å¼€ä¸å¥åº·çš„é€šé“
- **è¯„åˆ†å› ç´ **:
  - è¿ç»­å¤±è´¥ï¼šæ¯æ¬¡ -50 åˆ†
  - æœ€è¿‘å¤±è´¥ï¼ˆ5åˆ†é’Ÿå†…ï¼‰ï¼šæœ€å¤š -100 åˆ†
  - æˆåŠŸç‡ >90%ï¼š+30 åˆ†
  - æˆåŠŸç‡ <50%ï¼š-50 åˆ†
- **æ¢å¤**: å¤±è´¥é€šé“ä¼šéšæ—¶é—´è‡ªåŠ¨æ¢å¤ä¼˜å…ˆçº§

### æƒé‡ç­–ç•¥ (Weight)
- **ç›®çš„**: å°Šé‡ç®¡ç†å‘˜è®¾ç½®çš„é€šé“ä¼˜å…ˆçº§
- **è¯„åˆ†**: `é€šé“æƒé‡ / 100 * 100`
- **èŒƒå›´**: 0-100 åˆ†

### è¿æ¥æ„ŸçŸ¥ç­–ç•¥ (Connection)
- **ç›®çš„**: é¿å…å•ä¸ªé€šé“è¿‡è½½
- **è¯„åˆ†**: åŸºäºå½“å‰è¿æ¥ä½¿ç”¨ç‡
- **æœºåˆ¶**: ä½¿ç”¨ç‡è¶Šä½ï¼Œåˆ†æ•°è¶Šé«˜

## ğŸ”§ é«˜çº§é…ç½®

### å¯ç”¨è°ƒè¯•æ¨¡å¼
æŸ¥çœ‹è¯¦ç»†çš„è´Ÿè½½å‡è¡¡å†³ç­–è¿‡ç¨‹ï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export AXONHUB_LOAD_BALANCER_DEBUG=true

# æˆ–åœ¨è¯·æ±‚ä¸­å¯ç”¨
curl -X POST http://localhost:8090/v1/chat/completions \
  -H "X-Debug-Mode: true" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello"}]}'
```

### æŸ¥çœ‹å†³ç­–æ—¥å¿—
```bash
# æŸ¥çœ‹è´Ÿè½½å‡è¡¡å†³ç­–
tail -f axonhub.log | grep "Load balancing decision"

# æŸ¥çœ‹å…·ä½“é€šé“è¯„åˆ†
tail -f axonhub.log | grep "Channel load balancing details"

# ä½¿ç”¨ jq æ ¼å¼åŒ– JSON æ—¥å¿—
tail -f axonhub.log | jq 'select(.msg | contains("Load balancing"))'
```

## ğŸ“ˆ ç›‘æ§å’Œæ•…éšœæ’æŸ¥

### å…³é”®æŒ‡æ ‡
- **é€šé“åˆ‡æ¢é¢‘ç‡** - æ­£å¸¸æƒ…å†µä¸‹åº”è¯¥è¾ƒä½
- **é”™è¯¯ç‡åˆ†å¸ƒ** - æŸä¸ªé€šé“é”™è¯¯ç‡è¿‡é«˜å¯èƒ½éœ€è¦æ£€æŸ¥é…ç½®
- **å“åº”æ—¶é—´** - è´Ÿè½½å‡è¡¡åº”è¯¥ä¼˜åŒ–æ•´ä½“å“åº”æ—¶é—´

### å¸¸è§é—®é¢˜

**Q: ä¸ºä»€ä¹ˆè¯·æ±‚æ€»æ˜¯è·¯ç”±åˆ°åŒä¸€ä¸ªé€šé“ï¼Ÿ**
A: æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†ä¼šè¯ä¸€è‡´æ€§ã€‚åŒä¸€ trace ID çš„è¯·æ±‚ä¼šä¼˜å…ˆä½¿ç”¨ç›¸åŒé€šé“ã€‚

**Q: é€šé“ä¸åˆ‡æ¢æ€ä¹ˆåŠï¼Ÿ**
A: æŸ¥çœ‹é”™è¯¯æ„ŸçŸ¥ç­–ç•¥çš„è¯„åˆ†ã€‚é€šé“å¯èƒ½ä»ç„¶å¥åº·ï¼Œæˆ–è€…éœ€è¦æ—¶é—´æ¢å¤ã€‚

**Q: å¦‚ä½•éªŒè¯è´Ÿè½½å‡è¡¡æ˜¯å¦å·¥ä½œï¼Ÿ**
A: å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼ŒæŸ¥çœ‹æ—¥å¿—ä¸­çš„é€šé“è¯„åˆ†å’Œæ’åºã€‚

## ğŸ›ï¸ æœ€ä½³å®è·µ

### 1. é€šé“é…ç½®
- è®¾ç½®ä¸åŒçš„æƒé‡å€¼ä½“ç°ä¼˜å…ˆçº§
- é…ç½®å¤šä¸ªä¸åŒæä¾›å•†çš„é€šé“æé«˜å¯ç”¨æ€§
- å®šæœŸæ£€æŸ¥é€šé“å¥åº·çŠ¶æ€

### 2. ç›‘æ§è®¾ç½®
- ç›‘æ§å„é€šé“çš„é”™è¯¯ç‡å’Œå“åº”æ—¶é—´
- è®¾ç½®å‘Šè­¦å½“æŸä¸ªé€šé“æŒç»­å¤±è´¥
- å®šæœŸåˆ†æè´Ÿè½½å‡è¡¡å†³ç­–æ—¥å¿—

### 3. æ€§èƒ½ä¼˜åŒ–
- åœ°ç†ä½ç½®ç›¸è¿‘çš„é€šé“è®¾ç½®æ›´é«˜æƒé‡
- æ ¹æ®æˆæœ¬è€ƒè™‘è°ƒæ•´é€šé“ä¼˜å…ˆçº§
- ä½¿ç”¨ä¼šè¯ä¸€è‡´æ€§æé«˜ç”¨æˆ·ä½“éªŒ

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [ç»Ÿä¸€ API æ–‡æ¡£](../api-reference/unified-api.md)
- [é€šé“ç®¡ç†æŒ‡å—](../getting-started/quick-start.md)
- [è¿½è¸ªå’Œè°ƒè¯•](tracing.md)

---

