# Tracing Guide | 追踪指南

---

## English Version

### Overview
AxonHub captures every inbound request in a thread-aware trace without forcing you to adopt a new SDK. If your client already speaks the OpenAI-compatible protocol, you can opt into observability simply by forwarding trace and thread headers—or rely on AxonHub to create them for you automatically.

### Key Concepts
- **Trace ID (`AH-Trace-Id`)** – Unique identifier that stitches multiple requests together. You must provide this header when you need multiple requests to be linked; omitting it causes AxonHub to record requests separately even though it can auto-generate IDs.
- **Thread ID (`AH-Thread-Id`)** – Links a series of traces to the same conversation thread so you can follow user journeys end to end.
- **Extra Trace Headers** – Configure fallbacks (e.g. `Sentry-Trace`) to reuse existing observability tooling.

### Configuration
```yaml
# config.yml
trace:
  thread_header: "AH-Thread-Id"
  trace_header: "AH-Trace-Id"
  extra_trace_headers:
    - "Sentry-Trace"
```

- Set `extra_trace_headers` to reuse existing instrumentation headers.
- Leave headers empty to fall back to the defaults shown above.

### Using Tracing with OpenAI-Compatible Clients
```bash
curl https://your-axonhub-instance/v1/chat/completions \
  -H "Authorization: Bearer ${AXONHUB_API_KEY}" \
  -H "Content-Type: application/json" \
  -H "AH-Trace-Id: at-demo-123" \
  -H "AH-Thread-Id: thread-abc" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      { "role": "user", "content": "Diagnose latency in my pipeline" }
    ]
  }'
```

- Provide `AH-Trace-Id` when you need sequential requests to appear under the same trace. Without it AxonHub will log them independently, even though autogenerated IDs are available for standalone calls.
- All standard OpenAI SDKs work out of the box—no code changes beyond optional header injection.

### SDK Examples
Looking for complete runnable samples? See `integration_test/openai/trace_multiple_requests/trace_test.go` and `integration_test/anthropic/trace_multiple_requests/trace_test.go`. The snippets below extract the essentials for production code.

#### OpenAI Go SDK
```go
package traces

import (
    "context"

    "github.com/openai/openai-go/v3"
    "github.com/openai/openai-go/v3/option"
)

func sendTracedChat(ctx context.Context, apiKey string) (*openai.ChatCompletion, error) {
    client := openai.NewClient(
        option.WithAPIKey(apiKey),
        option.WithBaseURL("https://your-axonhub-instance/v1"),
        option.WithHeader("AH-Trace-Id", "trace-example-123"),
        option.WithHeader("AH-Thread-Id", "thread-example-abc"),
    )

    params := openai.ChatCompletionNewParams{
        Model: openai.ChatModel("gpt-4o"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.UserMessage("Diagnose latency in my pipeline"),
        },
    }

    ctx = context.WithValue(ctx, "trace_id", "trace-example-123")
    ctx = context.WithValue(ctx, "thread_id", "thread-example-abc")

    return client.Chat.Completions.New(ctx, params)
}
```

#### Anthropic Go SDK
```go
package traces

import (
    "context"

    anthropic "github.com/anthropics/anthropic-sdk-go"
    "github.com/anthropics/anthropic-sdk-go/option"
)

func sendTracedMessage(ctx context.Context, apiKey string) (*anthropic.Message, error) {
    client := anthropic.NewClient(
        option.WithAPIKey(apiKey),
        option.WithBaseURL("https://your-axonhub-instance/anthropic"),
        option.WithHeader("AH-Trace-Id", "trace-example-123"),
        option.WithHeader("AH-Thread-Id", "thread-example-abc"),
    )

    params := anthropic.MessageNewParams{
        Model: anthropic.Model("claude-3-5-sonnet"),
        Messages: []anthropic.MessageParam{
            anthropic.NewUserMessage(
                anthropic.NewTextBlock("Diagnose latency in my pipeline"),
            ),
        },
    }

    ctx = context.WithValue(ctx, "trace_id", "trace-example-123")
    ctx = context.WithValue(ctx, "thread_id", "thread-example-abc")

    return client.Messages.New(ctx, params)
}
```

### Data Storage for Trace Payloads
- Decide whether to keep full request/response bodies by adjusting your storage policy. Disable it if you only need metadata.
- Configure a default storage location in the admin console; AxonHub will fall back to the primary storage if the preferred option is unavailable.
- Large payloads can live in external storage (local disk, S3, or GCS) so traces stay responsive even when responses are big.

### Claude Code Trace Support
- Turn on Claude Code extraction with `server.trace.claude_code_trace_enabled: true` so AxonHub can pick up trace IDs automatically.
- The `/anthropic/v1/messages` endpoint will reuse the Claude Code `metadata.user_id` as the trace ID while keeping your payload untouched for downstream usage.
- If you already send a trace header, AxonHub keeps your value—manual instrumentation and auto-extraction work together.

### Exploring Traces in the Console
1. Navigate to **Traces** in the AxonHub admin console.
2. Filter by project, model, or time range to locate the trace of interest.
3. Expand a trace to inspect spans, prompt/response payloads, timing, and channel metadata.
4. Jump to the linked thread to review the overall conversation timeline alongside trace details.

### Troubleshooting
- **No trace recorded** – Ensure the request is authenticated and the project ID is resolved (API Key must belong to a project).
- **Missing thread linkage** – Provide `AH-Thread-Id` or create threads via the API before sending requests.
- **Unexpected trace IDs** – Check for upstream reverse proxies overriding headers.

---

## 中文版本

### 概览
AxonHub 可以在不引入额外 SDK 的情况下，为每一次请求构建线程感知的追踪。只要客户端已经兼容 OpenAI 协议，您就可以通过传递追踪与线程请求头，或直接让 AxonHub 自动生成，实现低侵入的可观测能力。

### 关键概念
- **Trace ID（`AH-Trace-Id`）** – 用于关联多次请求的唯一标识，需要在需要串联多次调用时显式提供；未携带该请求头时，AxonHub 会为单次调用生成 ID 但无法自动关联其他请求。
- **Thread ID（`AH-Thread-Id`）** – 将同一会话线程中的多条追踪关联起来，帮助重现完整的用户旅程。
- **额外追踪请求头** – 可配置备用请求头（如 `Sentry-Trace`），以复用已有的可观测工具链。

### 配置
```yaml
# config.yml
trace:
  thread_header: "AH-Thread-Id"
  trace_header: "AH-Trace-Id"
  extra_trace_headers:
    - "Sentry-Trace"
```

- 通过 `extra_trace_headers` 复用已有的埋点请求头。
- 如不配置，将采用上述默认值。

### 在 OpenAI 兼容客户端中使用追踪
```bash
curl https://your-axonhub-instance/v1/chat/completions \
  -H "Authorization: Bearer ${AXONHUB_API_KEY}" \
  -H "Content-Type: application/json" \
  -H "AH-Trace-Id: at-demo-123" \
  -H "AH-Thread-Id: thread-abc" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      { "role": "user", "content": "Diagnose latency in my pipeline" }
    ]
  }'
```

- 当需要让多次请求落在同一追踪中时，请显式提供 `AH-Trace-Id`；若缺失该请求头，AxonHub 会分别记录这些调用，即便会为单次请求生成 ID。
- 任何 OpenAI 兼容 SDK 均可直接使用，只需根据需要添加请求头即可。

### SDK 示例
如需完整可运行的样例，可参考 `integration_test/openai/trace_multiple_requests/trace_test.go` 与 `integration_test/anthropic/trace_multiple_requests/trace_test.go`。以下片段展示了在生产代码中最核心的部分。

#### OpenAI Go SDK
```go
package traces

import (
    "context"

    "github.com/openai/openai-go/v3"
    "github.com/openai/openai-go/v3/option"
)

func sendTracedChat(ctx context.Context, apiKey string) (*openai.ChatCompletion, error) {
    client := openai.NewClient(
        option.WithAPIKey(apiKey),
        option.WithBaseURL("https://your-axonhub-instance/v1"),
        option.WithHeader("AH-Trace-Id", "trace-example-123"),
        option.WithHeader("AH-Thread-Id", "thread-example-abc"),
    )

    params := openai.ChatCompletionNewParams{
        Model: openai.ChatModel("gpt-4o"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.UserMessage("请帮我诊断一下管道的延迟问题"),
        },
    }

    ctx = context.WithValue(ctx, "trace_id", "trace-example-123")
    ctx = context.WithValue(ctx, "thread_id", "thread-example-abc")

    return client.Chat.Completions.New(ctx, params)
}
```

#### Anthropic Go SDK
```go
package traces

import (
    "context"

    anthropic "github.com/anthropics/anthropic-sdk-go"
    "github.com/anthropics/anthropic-sdk-go/option"
)

func sendTracedMessage(ctx context.Context, apiKey string) (*anthropic.Message, error) {
    client := anthropic.NewClient(
        option.WithAPIKey(apiKey),
        option.WithBaseURL("https://your-axonhub-instance/anthropic"),
        option.WithHeader("AH-Trace-Id", "trace-example-123"),
        option.WithHeader("AH-Thread-Id", "thread-example-abc"),
    )

    params := anthropic.MessageNewParams{
        Model: anthropic.Model("claude-3-5-sonnet"),
        Messages: []anthropic.MessageParam{
            anthropic.NewUserMessage(
                anthropic.NewTextBlock("请帮我诊断一下管道的延迟问题"),
            ),
        },
    }

    ctx = context.WithValue(ctx, "trace_id", "trace-example-123")
    ctx = context.WithValue(ctx, "thread_id", "thread-example-abc")

    return client.Messages.New(ctx, params)
}
```

### 追踪数据存储
- 可在系统策略中决定是否保存完整请求／响应体：若仅需指标，可关闭以减少敏感数据留存。
- 在管理后台配置默认数据存储，若该存储不可用会自动回退到主存储，保障访问稳定。
- 大体量内容可放在外部存储（本地磁盘、S3、GCS），追踪页面仍能快速加载。

### Claude Code 追踪支持
- 将 `server.trace.claude_code_trace_enabled` 设为 `true`，AxonHub 会自动读取 Claude Code 产生的追踪 ID。
- `/anthropic/v1/messages` 的 `metadata.user_id` 会作为追踪 ID 使用，同时不会影响请求体给后续逻辑的读取。
- 如果请求已经带有追踪请求头，系统会优先使用该值，与自动提取机制兼容。

### 在控制台中探索追踪
1. 在 AxonHub 管理后台进入 **Traces** 页面。
2. 按项目、模型或时间范围筛选目标追踪。
3. 展开追踪查看 span、提示/回复内容、耗时及通道元数据。
4. 跳转关联的线程，结合追踪细节还原完整会话。

### 故障排查
- **未生成追踪** – 确认请求已通过认证且项目 ID 正确解析（API Key 必须隶属于某个项目）。
- **缺少线程关联** – 在请求中提供 `AH-Thread-Id`，或先通过 API 创建线程。
- **追踪 ID 异常** – 检查上游代理是否覆盖了相关请求头。

## Related Resources

- [Entity Relationship Diagram](../architecture/erd.md)
- [Fine-grained Permission Guide](permissions.md)
- [Claude Code Integration Guide](claude-code-integration.md)
- [Chat Completions API](../api-reference/unified-api.md#openai-chat-completions-api)
