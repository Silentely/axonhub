# Tracing Guide

---

### Overview
AxonHub captures every inbound request in a thread-aware trace without forcing you to adopt a new SDK. If your client already speaks the OpenAI-compatible protocol, you can opt into observability simply by forwarding trace and thread headers—or rely on AxonHub to create them for you automatically.

### Key Concepts
- **Trace ID (`AH-Trace-Id`)** – Unique identifier that stitches multiple requests together. You must provide this header when you need multiple requests to be linked; omitting it causes AxonHub to record requests separately even though it can auto-generate IDs.
- **Thread ID (`AH-Thread-Id`)** – Links a series of traces to the same conversation thread so you can follow user journeys end to end.
- **Extra Trace Headers** – Configure fallbacks (e.g. `Sentry-Trace`) to reuse existing observability tooling.

### Configuration
```yaml
# config.yml
trace:
  thread_header: "AH-Thread-Id"
  trace_header: "AH-Trace-Id"
  extra_trace_headers:
    - "Sentry-Trace"
```

- Set `extra_trace_headers` to reuse existing instrumentation headers.
- Leave headers empty to fall back to the defaults shown above.

### Using Tracing with OpenAI-Compatible Clients
```bash
curl https://your-axonhub-instance/v1/chat/completions \
  -H "Authorization: Bearer ${AXONHUB_API_KEY}" \
  -H "Content-Type: application/json" \
  -H "AH-Trace-Id: at-demo-123" \
  -H "AH-Thread-Id: thread-abc" \
  -d '{
    "model": "gpt-4o",
    "messages": [
      { "role": "user", "content": "Diagnose latency in my pipeline" }
    ]
  }'
```

- Provide `AH-Trace-Id` when you need sequential requests to appear under the same trace. Without it AxonHub will log them independently, even though autogenerated IDs are available for standalone calls.
- All standard OpenAI SDKs work out of the box—no code changes beyond optional header injection.

### SDK Examples
Looking for complete runnable samples? See `integration_test/openai/trace_multiple_requests/trace_test.go` and `integration_test/anthropic/trace_multiple_requests/trace_test.go`. The snippets below extract the essentials for production code.

#### OpenAI Go SDK
```go
package traces

import (
    "context"

    "github.com/openai/openai-go/v3"
    "github.com/openai/openai-go/v3/option"
)

func sendTracedChat(ctx context.Context, apiKey string) (*openai.ChatCompletion, error) {
    client := openai.NewClient(
        option.WithAPIKey(apiKey),
        option.WithBaseURL("https://your-axonhub-instance/v1"),
        option.WithHeader("AH-Trace-Id", "trace-example-123"),
        option.WithHeader("AH-Thread-Id", "thread-example-abc"),
    )

    params := openai.ChatCompletionNewParams{
        Model: openai.ChatModel("gpt-4o"),
        Messages: []openai.ChatCompletionMessageParamUnion{
            openai.UserMessage("Diagnose latency in my pipeline"),
        },
    }

    ctx = context.WithValue(ctx, "trace_id", "trace-example-123")
    ctx = context.WithValue(ctx, "thread_id", "thread-example-abc")

    return client.Chat.Completions.New(ctx, params)
}
```

#### Anthropic Go SDK
```go
package traces

import (
    "context"

    anthropic "github.com/anthropics/anthropic-sdk-go"
    "github.com/anthropics/anthropic-sdk-go/option"
)

func sendTracedMessage(ctx context.Context, apiKey string) (*anthropic.Message, error) {
    client := anthropic.NewClient(
        option.WithAPIKey(apiKey),
        option.WithBaseURL("https://your-axonhub-instance/anthropic"),
        option.WithHeader("AH-Trace-Id", "trace-example-123"),
        option.WithHeader("AH-Thread-Id", "thread-example-abc"),
    )

    params := anthropic.MessageNewParams{
        Model: anthropic.Model("claude-3-5-sonnet"),
        Messages: []anthropic.MessageParam{
            anthropic.NewUserMessage(
                anthropic.NewTextBlock("Diagnose latency in my pipeline"),
            ),
        },
    }

    ctx = context.WithValue(ctx, "trace_id", "trace-example-123")
    ctx = context.WithValue(ctx, "thread_id", "thread-example-abc")

    return client.Messages.New(ctx, params)
}
```

### Data Storage for Trace Payloads
- Decide whether to keep full request/response bodies by adjusting your storage policy. Disable it if you only need metadata.
- Configure a default storage location in the admin console; AxonHub will fall back to the primary storage if the preferred option is unavailable.
- Large payloads can live in external storage (local disk, S3, or GCS) so traces stay responsive even when responses are big.

### Claude Code Trace Support
- Turn on Claude Code extraction with `server.trace.claude_code_trace_enabled: true` so AxonHub can pick up trace IDs automatically.
- The `/anthropic/v1/messages` endpoint will reuse the Claude Code `metadata.user_id` as the trace ID while keeping your payload untouched for downstream usage.
- If you already send a trace header, AxonHub keeps your value—manual instrumentation and auto-extraction work together.

### Exploring Traces in the Console
1. Navigate to **Traces** in the AxonHub admin console.
2. Filter by project, model, or time range to locate the trace of interest.
3. Expand a trace to inspect spans, prompt/response payloads, timing, and channel metadata.
4. Jump to the linked thread to review the overall conversation timeline alongside trace details.

### Troubleshooting
- **No trace recorded** – Ensure the request is authenticated and the project ID is resolved (API Key must belong to a project).
- **Missing thread linkage** – Provide `AH-Thread-Id` or create threads via the API before sending requests.
- **Unexpected trace IDs** – Check for upstream reverse proxies overriding headers.
