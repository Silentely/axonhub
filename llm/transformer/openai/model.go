package openai

import (
	"encoding/json"
	"errors"

	"github.com/looplj/axonhub/llm"
)

// Request represents an OpenAI chat completion request.
// This is a clean OpenAI-specific model without helper fields.
type Request struct {
	// Messages is a list of messages to send to the model.
	Messages []Message `json:"messages" validator:"required,min=1"`

	// Model is the model ID used to generate the response.
	Model string `json:"model" validator:"required"`

	// FrequencyPenalty penalizes new tokens based on their existing frequency.
	FrequencyPenalty *float64 `json:"frequency_penalty,omitempty"`

	// Logprobs returns log probabilities of output tokens if true.
	Logprobs *bool `json:"logprobs,omitempty"`

	// MaxCompletionTokens is an upper bound for generated tokens.
	MaxCompletionTokens *int64 `json:"max_completion_tokens,omitempty"`

	// MaxTokens is deprecated in favor of max_completion_tokens.
	MaxTokens *int64 `json:"max_tokens,omitempty"`

	// PresencePenalty penalizes new tokens based on whether they appear in the text.
	PresencePenalty *float64 `json:"presence_penalty,omitempty"`

	// Seed for deterministic sampling.
	Seed *int64 `json:"seed,omitempty"`

	// Store whether to store the output for model distillation or evals.
	Store *bool `json:"store,omitzero"`

	// Temperature controls randomness (0-2).
	Temperature *float64 `json:"temperature,omitempty"`

	// TopLogprobs specifies number of most likely tokens to return.
	TopLogprobs *int64 `json:"top_logprobs,omitzero"`

	// TopP for nucleus sampling.
	TopP *float64 `json:"top_p,omitempty"`

	// PromptCacheKey is used by OpenAI to cache responses.
	PromptCacheKey *string `json:"prompt_cache_key,omitzero"`

	// SafetyIdentifier identifies users for abuse detection.
	SafetyIdentifier *string `json:"safety_identifier,omitzero"`

	// User is being replaced by safety_identifier and prompt_cache_key.
	User *string `json:"user,omitempty"`

	// LogitBias modifies likelihood of specified tokens.
	LogitBias map[string]int64 `json:"logit_bias,omitempty"`

	// Metadata is key-value pairs attached to the object.
	Metadata map[string]string `json:"metadata,omitempty"`

	// Modalities specifies output types (text, audio, image).
	Modalities []string `json:"modalities,omitempty"`

	// ReasoningEffort controls effort on reasoning models.
	ReasoningEffort string `json:"reasoning_effort,omitempty"`

	// ServiceTier specifies the processing type.
	ServiceTier *string `json:"service_tier,omitempty"`

	// Stop sequences where API will stop generating.
	Stop *Stop `json:"stop,omitempty"`

	Stream        *bool          `json:"stream,omitempty"`
	StreamOptions *StreamOptions `json:"stream_options,omitempty"`

	// ParallelToolCalls enables parallel function calling.
	ParallelToolCalls *bool       `json:"parallel_tool_calls,omitempty"`
	Tools             []Tool      `json:"tools,omitempty"`
	ToolChoice        *ToolChoice `json:"tool_choice,omitempty"`

	ResponseFormat *ResponseFormat `json:"response_format,omitempty"`

	// Verbosity constrains response verbosity.
	Verbosity *string `json:"verbosity,omitempty"`
}

// StreamOptions for streaming responses.
type StreamOptions struct {
	IncludeUsage bool `json:"include_usage,omitempty"`
}

// Stop represents stop sequences.
type Stop struct {
	Stop         *string
	MultipleStop []string
}

func (s Stop) MarshalJSON() ([]byte, error) {
	if s.Stop != nil {
		return json.Marshal(s.Stop)
	}

	if len(s.MultipleStop) > 0 {
		return json.Marshal(s.MultipleStop)
	}

	return []byte("[]"), nil
}

func (s *Stop) UnmarshalJSON(data []byte) error {
	var str string

	err := json.Unmarshal(data, &str)
	if err == nil {
		s.Stop = &str
		return nil
	}

	var strs []string

	err = json.Unmarshal(data, &strs)
	if err == nil {
		s.MultipleStop = strs
		return nil
	}

	return errors.New("invalid stop type")
}

// Message represents a message in the conversation.
type Message struct {
	Role    string         `json:"role,omitempty"`
	Content MessageContent `json:"content,omitzero"`
	Name    *string        `json:"name,omitempty"`

	// Refusal message generated by the model.
	Refusal string `json:"refusal,omitempty"`

	// For tool call response.
	ToolCallID *string    `json:"tool_call_id,omitempty"`
	ToolCalls  []ToolCall `json:"tool_calls,omitempty"`

	// ReasoningContent for deepseek-reasoner support.
	ReasoningContent *string `json:"reasoning_content,omitempty"`
}

// MessageContent represents message content (string or array of parts).
type MessageContent struct {
	Content         *string              `json:"content,omitempty"`
	MultipleContent []MessageContentPart `json:"multiple_content,omitempty"`
}

func (c MessageContent) MarshalJSON() ([]byte, error) {
	if len(c.MultipleContent) > 0 {
		if len(c.MultipleContent) == 1 && c.MultipleContent[0].Type == "text" {
			return json.Marshal(c.MultipleContent[0].Text)
		}

		return json.Marshal(c.MultipleContent)
	}

	return json.Marshal(c.Content)
}

func (c *MessageContent) UnmarshalJSON(data []byte) error {
	if len(data) == 0 || string(data) == "null" {
		c.Content = nil
		c.MultipleContent = nil

		return nil
	}

	var str string

	err := json.Unmarshal(data, &str)
	if err == nil {
		c.Content = &str
		return nil
	}

	var parts []MessageContentPart

	err = json.Unmarshal(data, &parts)
	if err == nil {
		c.MultipleContent = parts
		return nil
	}

	return errors.New("invalid content type")
}

// MessageContentPart represents different types of content (text, image, etc.)
type MessageContentPart struct {
	Type     string    `json:"type"`
	Text     *string   `json:"text,omitempty"`
	ImageURL *ImageURL `json:"image_url,omitempty"`
	Audio    *Audio    `json:"audio,omitempty"`
}

// ImageURL represents an image URL with optional detail level.
type ImageURL struct {
	URL    string  `json:"url"`
	Detail *string `json:"detail,omitempty"`
}

// Audio represents audio content.
type Audio struct {
	Format string `json:"format"`
	Data   string `json:"data"`
}

// ResponseFormat specifies the format of the response.
type ResponseFormat struct {
	Type       string          `json:"type"`
	JSONSchema json.RawMessage `json:"json_schema,omitempty"`
}

// Response represents an OpenAI chat completion response.
type Response struct {
	ID      string   `json:"id"`
	Choices []Choice `json:"choices"`
	Object  string   `json:"object"`
	Created int64    `json:"created"`
	Model   string   `json:"model"`
	Usage   *Usage   `json:"usage,omitempty"`

	SystemFingerprint string `json:"system_fingerprint,omitempty"`
	ServiceTier       string `json:"service_tier,omitempty"`

	Error *OpenAIError `json:"error,omitempty"`
}

// Choice represents a choice in the response.
type Choice struct {
	Index        int       `json:"index"`
	Message      *Message  `json:"message,omitempty"`
	Delta        *Message  `json:"delta,omitempty"`
	FinishReason *string   `json:"finish_reason,omitempty"`
	Logprobs     *Logprobs `json:"logprobs,omitempty"`
}

// Logprobs represents logprobs information.
type Logprobs struct {
	Content []TokenLogprob `json:"content"`
}

// TokenLogprob represents logprob for a token.
type TokenLogprob struct {
	Token       string       `json:"token"`
	Logprob     float64      `json:"logprob"`
	Bytes       []int        `json:"bytes,omitempty"`
	TopLogprobs []TopLogprob `json:"top_logprobs,omitempty"`
}

// TopLogprob represents top alternative tokens.
type TopLogprob struct {
	Token   string  `json:"token"`
	Logprob float64 `json:"logprob"`
	Bytes   []int   `json:"bytes,omitempty"`
}

// OpenAIError represents an error response.
type OpenAIError struct {
	StatusCode int             `json:"-"`
	Detail     llm.ErrorDetail `json:"error"`
}

// Tool represents a function tool.
type Tool struct {
	Type     string   `json:"type"`
	Function Function `json:"function"`
}

// ToLLMTool converts OpenAI Tool to unified llm.Tool.
func (t Tool) ToLLMTool() llm.Tool {
	return llm.Tool{
		Type: t.Type,
		Function: llm.Function{
			Name:        t.Function.Name,
			Description: t.Function.Description,
			Parameters:  t.Function.Parameters,
			Strict:      t.Function.Strict,
		},
	}
}

// Function represents a function definition.
type Function struct {
	Name        string          `json:"name"`
	Description string          `json:"description,omitempty"`
	Parameters  json.RawMessage `json:"parameters"`
	Strict      *bool           `json:"strict,omitempty"`
}

// FunctionCall represents a function call.
type FunctionCall struct {
	Name      string `json:"name"`
	Arguments string `json:"arguments"`
}

// ToolCall represents a tool call in the response.
type ToolCall struct {
	ID       string       `json:"id,omitempty"`
	Type     string       `json:"type,omitempty"`
	Function FunctionCall `json:"function"`
	Index    int          `json:"index"`
}

// ToolFunction represents a tool function reference.
type ToolFunction struct {
	Name string `json:"name"`
}

// ToolChoice represents the tool choice parameter.
type ToolChoice struct {
	ToolChoice      *string          `json:"tool_choice,omitempty"`
	NamedToolChoice *NamedToolChoice `json:"named_tool_choice,omitempty"`
}

// NamedToolChoice represents a named tool choice.
type NamedToolChoice struct {
	Type     string       `json:"type"`
	Function ToolFunction `json:"function"`
}

func (t ToolChoice) MarshalJSON() ([]byte, error) {
	if t.ToolChoice != nil {
		return json.Marshal(t.ToolChoice)
	}

	return json.Marshal(t.NamedToolChoice)
}

func (t *ToolChoice) UnmarshalJSON(data []byte) error {
	var str string

	err := json.Unmarshal(data, &str)
	if err == nil {
		t.ToolChoice = &str
		return nil
	}

	var named NamedToolChoice

	err = json.Unmarshal(data, &named)
	if err == nil {
		t.NamedToolChoice = &named
		return nil
	}

	return errors.New("invalid tool choice type")
}
