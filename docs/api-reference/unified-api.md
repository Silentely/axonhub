# Unified API Reference

## Overview

AxonHub provides a unified API gateway that supports both OpenAI Chat Completions and Anthropic Messages APIs through a single interface. This allows you to use existing OpenAI or Anthropic client SDKs while seamlessly accessing models from multiple providers. The platform automatically handles API format translation, enabling you to use one API format to access models from any supported provider.

## Key Benefits

- **API Interoperability**: Use OpenAI Chat Completions API to call Anthropic models, or use Anthropic Messages API to call OpenAI models
- **Zero Code Changes**: Keep using your existing OpenAI or Anthropic client SDKs without modification
- **Automatic Translation**: AxonHub automatically converts between API formats when needed
- **Provider Flexibility**: Access any supported AI provider regardless of which API format you prefer

## Supported API Formats

### OpenAI Chat Completions API

AxonHub fully supports the OpenAI Chat Completions API specification, allowing you to use any OpenAI-compatible client SDK.

**Endpoints:**
- `POST /v1/chat/completions` - Text generation
- `GET /v1/models` - List available models

**Example Request:**
```python
from openai import OpenAI

client = OpenAI(
    api_key="your-axonhub-api-key",
    base_url="http://localhost:8090/v1"
)

# Call Anthropic model using OpenAI API format
response = client.chat.completions.create(
    model="claude-3-5-sonnet",
    messages=[
        {"role": "user", "content": "Hello, Claude!"}
    ]
)
print(response.choices[0].message.content)
```

### Anthropic Messages API

AxonHub also supports the native Anthropic Messages API for applications that prefer Anthropic's specific features and response format.

**Endpoints:**
- `POST /anthropic/v1/messages` - Text generation
- `GET /anthropic/v1/models` - List available models

**Example Request:**
```python
import requests

response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={
        "Content-Type": "application/json",
        "X-API-Key": "your-axonhub-api-key"
    },
    json={
        "model": "gpt-4o",
        "max_tokens": 512,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Hello, GPT!"}
                ]
            }
        ]
    }
)
print(response.json()["content"][0]["text"])
```

## API Translation Capabilities

AxonHub automatically translates between API formats, enabling these powerful scenarios:

### Use OpenAI SDK with Anthropic Models
```python
# OpenAI SDK calling Anthropic model
response = client.chat.completions.create(
    model="claude-3-5-sonnet",  # Anthropic model
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)
# AxonHub automatically translates OpenAI format â†’ Anthropic format
```

### Use Anthropic SDK with OpenAI Models
```python
# Anthropic SDK calling OpenAI model
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    json={
        "model": "gpt-4o",  # OpenAI model
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Hello!"}]
            }
        ]
    }
)
# AxonHub automatically translates Anthropic format â†’ OpenAI format
```

## Supported Providers

| Provider               | Status     | Supported Models             | Compatible APIs |
| ---------------------- | ---------- | ---------------------------- | --------------- |
| **OpenAI**             | âœ… Done    | GPT-4, GPT-4o, GPT-5, etc.   | OpenAI, Anthropic |
| **Anthropic**          | âœ… Done    | Claude 3.5, Claude 3.0, etc. | OpenAI, Anthropic |
| **Zhipu AI**           | âœ… Done    | GLM-4.5, GLM-4.5-air, etc.   | OpenAI, Anthropic |
| **Moonshot AI (Kimi)** | âœ… Done    | kimi-k2, etc.                | OpenAI, Anthropic |
| **DeepSeek**           | âœ… Done    | DeepSeek-V3.1, etc.          | OpenAI, Anthropic |
| **ByteDance Doubao**   | âœ… Done    | doubao-1.6, etc.             | OpenAI, Anthropic |
| **Gemini**             | âœ… Done    | Gemini 2.5, etc.             | OpenAI, Anthropic |
| **AWS Bedrock**        | ğŸ”„ Testing | Claude on AWS                | OpenAI, Anthropic |
| **Google Cloud**       | ğŸ”„ Testing | Claude on GCP                | OpenAI, Anthropic |

## Authentication

Both API formats use the same authentication system:

- **OpenAI API**: Use `Authorization: Bearer <your-api-key>` header
- **Anthropic API**: Use `X-API-Key: <your-api-key>` header

The API keys are managed through AxonHub's API Key management system and provide the same permissions regardless of which API format you use.

## Streaming Support

Both API formats support streaming responses:

### OpenAI Streaming
```python
response = client.chat.completions.create(
    model="claude-3-5-sonnet",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### Anthropic Streaming
```python
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={
        "Content-Type": "application/json",
        "X-API-Key": "your-api-key",
        "Accept": "text/event-stream"
    },
    json={
        "model": "gpt-4o",
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Tell me a story"}]
            }
        ],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

## Error Handling

Both API formats return standardized error responses:

### OpenAI Format Error
```json
{
  "error": {
    "message": "Invalid API key",
    "type": "invalid_request_error",
    "code": "invalid_api_key"
  }
}
```

### Anthropic Format Error
```json
{
  "type": "error",
  "error": {
    "type": "invalid_request_error",
    "message": "Invalid API key"
  }
}
```

## Best Practices

1. **Choose Your Preferred API**: Use the API format that best fits your application's needs and existing codebase
2. **Consistent Authentication**: Use the same API key across both API formats
3. **Model Selection**: Specify the target model explicitly in your requests
4. **Error Handling**: Implement proper error handling for both API formats
5. **Streaming**: Use streaming for better user experience with long responses

## Migration Guide

### From OpenAI to AxonHub
```python
# Before: Direct OpenAI
client = OpenAI(api_key="openai-key")

# After: AxonHub with OpenAI API
client = OpenAI(
    api_key="axonhub-api-key",
    base_url="http://localhost:8090/v1"
)
# Your existing code continues to work!
```

### From Anthropic to AxonHub
```python
# Before: Direct Anthropic
response = requests.post(
    "https://api.anthropic.com/v1/messages",
    headers={"X-API-Key": "anthropic-key"}
)

# After: AxonHub with Anthropic API
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={"X-API-Key": "axonhub-api-key"}
)
# Your existing code continues to work!
```

---

# ç»Ÿä¸€ API å‚è€ƒ

## æ¦‚è¿°

AxonHub æä¾›ç»Ÿä¸€çš„ API ç½‘å…³ï¼Œé€šè¿‡å•ä¸€æ¥å£åŒæ—¶æ”¯æŒ OpenAI Chat Completions å’Œ Anthropic Messages APIã€‚è¿™ä½¿æ‚¨å¯ä»¥åœ¨ä½¿ç”¨ç°æœ‰ OpenAI æˆ– Anthropic å®¢æˆ·ç«¯ SDK çš„åŒæ—¶ï¼Œæ— ç¼è®¿é—®å¤šä¸ªæä¾›å•†çš„æ¨¡å‹ã€‚å¹³å°è‡ªåŠ¨å¤„ç† API æ ¼å¼è½¬æ¢ï¼Œè®©æ‚¨å¯ä»¥ä½¿ç”¨ä¸€ç§ API æ ¼å¼è®¿é—®ä»»ä½•æ”¯æŒçš„æä¾›å•†ã€‚

## æ ¸å¿ƒä¼˜åŠ¿

- **API äº’æ“ä½œæ€§**ï¼šä½¿ç”¨ OpenAI Chat Completions API è°ƒç”¨ Anthropic æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨ Anthropic Messages API è°ƒç”¨ OpenAI æ¨¡å‹
- **é›¶ä»£ç å˜æ›´**ï¼šç»§ç»­ä½¿ç”¨ç°æœ‰çš„ OpenAI æˆ– Anthropic å®¢æˆ·ç«¯ SDKï¼Œæ— éœ€ä¿®æ”¹
- **è‡ªåŠ¨è½¬æ¢**ï¼šAxonHub åœ¨éœ€è¦æ—¶è‡ªåŠ¨åœ¨ API æ ¼å¼ä¹‹é—´è¿›è¡Œè½¬æ¢
- **æä¾›å•†çµæ´»æ€§**ï¼šæ— è®ºæ‚¨åå¥½å“ªç§ API æ ¼å¼ï¼Œéƒ½å¯ä»¥è®¿é—®ä»»ä½•æ”¯æŒçš„ AI æä¾›å•†

## æ”¯æŒçš„ API æ ¼å¼

### OpenAI Chat Completions API

AxonHub å®Œå…¨æ”¯æŒ OpenAI Chat Completions API è§„èŒƒï¼Œå…è®¸æ‚¨ä½¿ç”¨ä»»ä½• OpenAI å…¼å®¹çš„å®¢æˆ·ç«¯ SDKã€‚

**ç«¯ç‚¹ï¼š**
- `POST /v1/chat/completions` - æ–‡æœ¬ç”Ÿæˆ
- `GET /v1/models` - åˆ—å‡ºå¯ç”¨æ¨¡å‹

**ç¤ºä¾‹è¯·æ±‚ï¼š**
```python
from openai import OpenAI

client = OpenAI(
    api_key="your-axonhub-api-key",
    base_url="http://localhost:8090/v1"
)

# ä½¿ç”¨ OpenAI API æ ¼å¼è°ƒç”¨ Anthropic æ¨¡å‹
response = client.chat.completions.create(
    model="claude-3-5-sonnet",
    messages=[
        {"role": "user", "content": "Hello, Claude!"}
    ]
)
print(response.choices[0].message.content)
```

### Anthropic Messages API

AxonHub è¿˜æ”¯æŒåŸç”Ÿ Anthropic Messages APIï¼Œé€‚ç”¨äºåå¥½ Anthropic ç‰¹å®šåŠŸèƒ½å’Œå“åº”æ ¼å¼çš„åº”ç”¨ç¨‹åºã€‚

**ç«¯ç‚¹ï¼š**
- `POST /anthropic/v1/messages` - æ–‡æœ¬ç”Ÿæˆ
- `GET /anthropic/v1/models` - åˆ—å‡ºå¯ç”¨æ¨¡å‹

**ç¤ºä¾‹è¯·æ±‚ï¼š**
```python
import requests

response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={
        "Content-Type": "application/json",
        "X-API-Key": "your-axonhub-api-key"
    },
    json={
        "model": "gpt-4o",
        "max_tokens": 512,
        "messages": [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "Hello, GPT!"}
                ]
            }
        ]
    }
)
print(response.json()["content"][0]["text"])
```

## API è½¬æ¢èƒ½åŠ›

AxonHub è‡ªåŠ¨åœ¨ API æ ¼å¼ä¹‹é—´è¿›è¡Œè½¬æ¢ï¼Œå®ç°ä»¥ä¸‹å¼ºå¤§åœºæ™¯ï¼š

### ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Anthropic æ¨¡å‹
```python
# OpenAI SDK è°ƒç”¨ Anthropic æ¨¡å‹
response = client.chat.completions.create(
    model="claude-3-5-sonnet",  # Anthropic æ¨¡å‹
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)
# AxonHub è‡ªåŠ¨è½¬æ¢ OpenAI æ ¼å¼ â†’ Anthropic æ ¼å¼
```

### ä½¿ç”¨ Anthropic SDK è°ƒç”¨ OpenAI æ¨¡å‹
```python
# Anthropic SDK è°ƒç”¨ OpenAI æ¨¡å‹
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    json={
        "model": "gpt-4o",  # OpenAI æ¨¡å‹
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Hello!"}]
            }
        ]
    }
)
# AxonHub è‡ªåŠ¨è½¬æ¢ Anthropic æ ¼å¼ â†’ OpenAI æ ¼å¼
```

## æ”¯æŒçš„æä¾›å•†

| æä¾›å•†                   | çŠ¶æ€       | æ”¯æŒæ¨¡å‹ç¤ºä¾‹                 | å…¼å®¹ API |
| ------------------------ | ---------- | ---------------------------- | --------------- |
| **OpenAI**               | âœ… å·²å®Œæˆ  | GPT-4ã€GPT-4oã€GPT-5 ç­‰      | OpenAI, Anthropic |
| **Anthropic**            | âœ… å·²å®Œæˆ  | Claude 3.5ã€Claude 3.0 ç­‰    | OpenAI, Anthropic |
| **æ™ºè°± AIï¼ˆZhipuï¼‰**     | âœ… å·²å®Œæˆ  | GLM-4.5ã€GLM-4.5-air ç­‰      | OpenAI, Anthropic |
| **æœˆä¹‹æš—é¢ï¼ˆMoonshotï¼‰** | âœ… å·²å®Œæˆ  | kimi-k2 ç­‰                   | OpenAI, Anthropic |
| **DeepSeek**             | âœ… å·²å®Œæˆ  | DeepSeek-V3.1 ç­‰             | OpenAI, Anthropic |
| **å­—èŠ‚è·³åŠ¨è±†åŒ…**         | âœ… å·²å®Œæˆ  | doubao-1.6 ç­‰                | OpenAI, Anthropic |
| **Gemini**               | âœ… å·²å®Œæˆ  | Gemini 2.5 ç­‰                | OpenAI, Anthropic |
| **AWS Bedrock**          | ğŸ”„ æµ‹è¯•ä¸­  | Claude on AWS                | OpenAI, Anthropic |
| **Google Cloud**         | ğŸ”„ æµ‹è¯•ä¸­  | Claude on GCP                | OpenAI, Anthropic |

## è®¤è¯

ä¸¤ç§ API æ ¼å¼ä½¿ç”¨ç›¸åŒçš„è®¤è¯ç³»ç»Ÿï¼š

- **OpenAI API**ï¼šä½¿ç”¨ `Authorization: Bearer <your-api-key>` å¤´éƒ¨
- **Anthropic API**ï¼šä½¿ç”¨ `X-API-Key: <your-api-key>` å¤´éƒ¨

API å¯†é’¥é€šè¿‡ AxonHub çš„ API å¯†é’¥ç®¡ç†ç³»ç»Ÿè¿›è¡Œç®¡ç†ï¼Œæ— è®ºä½¿ç”¨å“ªç§ API æ ¼å¼ï¼Œéƒ½æä¾›ç›¸åŒçš„æƒé™ã€‚

## æµå¼æ”¯æŒ

ä¸¤ç§ API æ ¼å¼éƒ½æ”¯æŒæµå¼å“åº”ï¼š

### OpenAI æµå¼
```python
response = client.chat.completions.create(
    model="claude-3-5-sonnet",
    messages=[{"role": "user", "content": "Tell me a story"}],
    stream=True
)

for chunk in response:
    if chunk.choices[0].delta.content:
        print(chunk.choices[0].delta.content, end="")
```

### Anthropic æµå¼
```python
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={
        "Content-Type": "application/json",
        "X-API-Key": "your-api-key",
        "Accept": "text/event-stream"
    },
    json={
        "model": "gpt-4o",
        "messages": [
            {
                "role": "user",
                "content": [{"type": "text", "text": "Tell me a story"}]
            }
        ],
        "stream": True
    },
    stream=True
)

for line in response.iter_lines():
    if line:
        print(line.decode('utf-8'))
```

## é”™è¯¯å¤„ç†

ä¸¤ç§ API æ ¼å¼éƒ½è¿”å›æ ‡å‡†åŒ–çš„é”™è¯¯å“åº”ï¼š

### OpenAI æ ¼å¼é”™è¯¯
```json
{
  "error": {
    "message": "Invalid API key",
    "type": "invalid_request_error",
    "code": "invalid_api_key"
  }
}
```

### Anthropic æ ¼å¼é”™è¯¯
```json
{
  "type": "error",
  "error": {
    "type": "invalid_request_error",
    "message": "Invalid API key"
  }
}
```

## æœ€ä½³å®è·µ

1. **é€‰æ‹©åå¥½çš„ API**ï¼šä½¿ç”¨æœ€é€‚åˆåº”ç”¨ç¨‹åºéœ€æ±‚å’Œç°æœ‰ä»£ç åº“çš„ API æ ¼å¼
2. **ä¸€è‡´çš„è®¤è¯**ï¼šåœ¨ä¸¤ç§ API æ ¼å¼ä¸­ä½¿ç”¨ç›¸åŒçš„ API å¯†é’¥
3. **æ¨¡å‹é€‰æ‹©**ï¼šåœ¨è¯·æ±‚ä¸­æ˜ç¡®æŒ‡å®šç›®æ ‡æ¨¡å‹
4. **é”™è¯¯å¤„ç†**ï¼šä¸ºä¸¤ç§ API æ ¼å¼å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†
5. **æµå¼å¤„ç†**ï¼šå¯¹äºé•¿å“åº”ä½¿ç”¨æµå¼å¤„ç†ä»¥è·å¾—æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

## è¿ç§»æŒ‡å—

### ä» OpenAI è¿ç§»åˆ° AxonHub
```python
# ä¹‹å‰ï¼šç›´æ¥ OpenAI
client = OpenAI(api_key="openai-key")

# ä¹‹åï¼šä½¿ç”¨ OpenAI API çš„ AxonHub
client = OpenAI(
    api_key="axonhub-api-key",
    base_url="http://localhost:8090/v1"
)
# æ‚¨çš„ç°æœ‰ä»£ç ç»§ç»­å·¥ä½œï¼
```

### ä» Anthropic è¿ç§»åˆ° AxonHub
```python
# ä¹‹å‰ï¼šç›´æ¥ Anthropic
response = requests.post(
    "https://api.anthropic.com/v1/messages",
    headers={"X-API-Key": "anthropic-key"}
)

# ä¹‹åï¼šä½¿ç”¨ Anthropic API çš„ AxonHub
response = requests.post(
    "http://localhost:8090/anthropic/v1/messages",
    headers={"X-API-Key": "axonhub-api-key"}
)
# æ‚¨çš„ç°æœ‰ä»£ç ç»§ç»­å·¥ä½œï¼
```